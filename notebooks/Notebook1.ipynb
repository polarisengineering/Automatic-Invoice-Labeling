{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JSZlS9QUNdf"
      },
      "outputs": [],
      "source": [
        "#PRIMA CELLA NON UTILE PERCHE' QUESTO APPROCCIO BASATO SULLA RETE WORD2VEC E' STATO POI ABBANDONATO IN FAVORE DELL'USO DI\n",
        "#BAG OF WORDS CHE E' PIU' SEMPLICE, PIU' GENERALIZZABILE E OFFRE PERFORMANCE SOLO DI POCO INFERIORI\n",
        "\n",
        "\"\"\"\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "%cd fastText\n",
        "!sudo pip install .\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "fasttext.util.download_model('it', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.it.300.bin')\n",
        "print(ft.get_dimension())\n",
        "\n",
        "similarity_materie_prime = []\n",
        "similarity_materie_consumo = []\n",
        "similarity_merci = []\n",
        "similarity_merci_prodotti = []\n",
        "\n",
        "vector_formaggio = ft.get_word_vector('formaggio')\n",
        "vector_uova = ft.get_word_vector('uova')\n",
        "vector_busta = ft.get_word_vector('busta')\n",
        "vector_posate = ft.get_word_vector('posate')\n",
        "vector_kinder = ft.get_word_vector('kinder')\n",
        "vector_caramella = ft.get_word_vector('caramella')\n",
        "vector_bibita = ft.get_word_vector('bibita')\n",
        "vector_vodka = ft.get_word_vector('vodka')\n",
        "\n",
        "for s in list(descr):\n",
        "  s = s.lower()\n",
        "  s_words = s.split(\" \")\n",
        "\n",
        "  words_similarities_materie_prime = []\n",
        "  words_similarities_materie_consumo = []\n",
        "  words_similarities_merci = []\n",
        "  words_similarities_merci_prodotti = []\n",
        "\n",
        "  for i in s_words:\n",
        "    vector_i = ft.get_word_vector(i)\n",
        "    score_materie_prime = ((1 - spatial.distance.cosine(vector_i, vector_formaggio)) + (1 - spatial.distance.cosine(vector_i, vector_uova)))/2\n",
        "    score_materie_consumo = ((1 - spatial.distance.cosine(vector_i, vector_busta)) + (1 - spatial.distance.cosine(vector_i, vector_posate)))/2\n",
        "    score_merci = ((1 - spatial.distance.cosine(vector_i, vector_kinder)) + (1 - spatial.distance.cosine(vector_i, vector_caramella)))/2\n",
        "    score_merci_prodotti = ((1 - spatial.distance.cosine(vector_i, vector_bibita)) + (1 - spatial.distance.cosine(vector_i, vector_vodka)))/2\n",
        "\n",
        "    words_similarities_materie_prime.append(score_materie_prime)\n",
        "    words_similarities_materie_consumo.append(score_materie_consumo)\n",
        "    words_similarities_merci.append(score_merci)\n",
        "    words_similarities_merci_prodotti.append(score_merci_prodotti)\n",
        "\n",
        "  words_similarities_materie_prime = [x for x in words_similarities_materie_prime if pd.notnull(x)]\n",
        "  words_similarities_materie_consumo = [x for x in words_similarities_materie_consumo if pd.notnull(x)]\n",
        "  words_similarities_merci = [x for x in words_similarities_merci if pd.notnull(x)]\n",
        "  words_similarities_merci_prodotti = [x for x in words_similarities_merci_prodotti if pd.notnull(x)]\n",
        "\n",
        "  best_materie_prime = max(words_similarities_materie_prime)\n",
        "  best_materie_consumo = max(words_similarities_materie_consumo)\n",
        "  best_merci = max(words_similarities_merci)\n",
        "  best_merci_prodotti = max(words_similarities_merci_prodotti)\n",
        "\n",
        "  similarity_materie_prime.append(best_materie_prime)\n",
        "  similarity_materie_consumo.append(best_materie_consumo)\n",
        "  similarity_merci.append(best_merci)\n",
        "  similarity_merci_prodotti.append(best_merci_prodotti)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTEBOOK 1: data cleaning, feature selection e fitting di modelli di classificazione, con analisi delle performance e degli errori commessi.\n",
        "#La prima cella è dedicata a settare la rete Word2Vec in italiano che serve a estrarre features semantiche dalle descrizioni \n",
        "#delle fatture in modo da distinguere meglio le classi\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-qYyUrenIc5",
        "outputId": "ea276437-e650-43ea-b65e-611b2bcecf94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rDJeckHKZ0Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bedb0771-6b18-4958-ac03-7c93d576f814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceValore_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_ScontoMaggiorazione_Tipo_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_ScontoMaggiorazione_Percentuale_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_ScontoMaggiorazione_Importo_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AltriDatiGestionali_TipoDato_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AltriDatiGestionali_RiferimentoTesto_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AltriDatiGestionali_RiferimentoNumero_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AltriDatiGestionali_RiferimentoData_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_NumeroLinea',\n",
            "       ...\n",
            "       'N. Doc.', 'Data Doc.', 'Causale', 'Conto',\n",
            "       'Rag. Sociale / Descrizione', 'Importo', 'D/A', 'G', 'A', 'ND ori.'],\n",
            "      dtype='object', length=224)\n",
            "(5877, 224)\n"
          ]
        }
      ],
      "source": [
        "#lettura in pandas del file excel che contiene la relazione input-output matchando fatture XML e prima nota\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_excel('/content/drive/MyDrive/df_final.xlsx')\n",
        "data = data.drop('Unnamed: 0', axis=1)\n",
        "#print(data.head(5))\n",
        "print(data.columns)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selezione delle colonne di interesse\n",
        "\n",
        "data = data[['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_Descrizione',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale',\n",
        "            'FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA',\n",
        "            'FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT',\n",
        "            'Conto']]\n",
        "\n",
        "print(data.shape)\n",
        "#print(data.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz1pj_kKJ7NO",
        "outputId": "e167183d-a197-4093-e1eb-fd945ef2b825"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5877, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo del tipo delle colonne\n",
        "\n",
        "for column in data.columns:\n",
        "  print(column)\n",
        "  print(type(data[column][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0wSiUuvJ7Qu",
        "outputId": "d179db39-8c42-4931-e0af-8836066f633a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero\n",
            "<class 'str'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first\n",
            "<class 'str'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario\n",
            "<class 'numpy.float64'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale\n",
            "<class 'numpy.float64'>\n",
            "FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first\n",
            "<class 'str'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA\n",
            "<class 'numpy.float64'>\n",
            "FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice\n",
            "<class 'numpy.int64'>\n",
            "FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data\n",
            "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
            "FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT\n",
            "<class 'str'>\n",
            "Conto\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conversione del tipo di dato in alcune colonne\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "data['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA'] = data['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA'].astype(int)\n",
        "data['FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice'] = data['FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice'].astype(str)\n"
      ],
      "metadata": {
        "id": "usEqzUHiJ7Tq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conversione della data in 3 colonne giorno-mese-anno per renderle feature adatte a fare machine learning, e\n",
        "#conseguente eliminazione della colonna con la data in formato timestamp\n",
        "\n",
        "year = pd.Series(pd.DatetimeIndex(data['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data']).year)\n",
        "month = pd.Series(pd.DatetimeIndex(data['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data']).month)\n",
        "day = pd.Series(pd.DatetimeIndex(data['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data']).day)\n",
        "\n",
        "frame = {'year': year, 'month': month, 'day': day}\n",
        "data2 = pd.DataFrame(frame)\n",
        "  \n",
        "data = pd.concat(objs=[data, data2], axis=1)\n",
        "data.drop('FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data', axis=1, inplace=True)\n",
        "\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9v-rbLHwUCl",
        "outputId": "c7cb0a93-0726-46af-f5cf-732e8042ffe3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_Descrizione',\n",
            "       'FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale',\n",
            "       'FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA',\n",
            "       'FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice',\n",
            "       'FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT', 'Conto',\n",
            "       'year', 'month', 'day'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rinominazione delle colonne\n",
        "\n",
        "data = data.rename(columns={'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_Descrizione': 'Descrizione',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero': 'Numero',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first': 'CodiceTipo',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario': 'PrezzoUnitario',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale': 'PrezzoTotale',\n",
        "            'FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first': 'ModalitaPagamento',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA': 'AliquotaIVA',\n",
        "            'FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice': 'CodiceCedente',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT': 'NumeroDDT',\n",
        "            'Conto': 'Conto', 'year': 'Year', 'month': 'Month', 'day': 'Day'})\n",
        "\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGGSzrSmEA6H",
        "outputId": "01a05e10-a2f4-4d6d-8f8a-436c44fe163f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Descrizione', 'Numero', 'CodiceTipo', 'PrezzoUnitario', 'PrezzoTotale',\n",
            "       'ModalitaPagamento', 'AliquotaIVA', 'CodiceCedente', 'NumeroDDT',\n",
            "       'Conto', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminazione, in tutte le colonne tranne 'Conto', dei nan che compaiono come float a favore di stringhe vuote \n",
        "#(perche tutte le colonne di feature con dei nan sono in formato stringa)\n",
        "\n",
        "Conti = data.Conto\n",
        "data = data.fillna('')\n",
        "data.Conto = Conti\n",
        "print(data.isnull().sum().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40nyRgdM5Bm1",
        "outputId": "f38d5756-8955-4936-da2d-0bfbab9de0aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#semplificazione N1: tutte le features categoriche vengono gestite col semplice One Hot Encoding, anche se questo causa\n",
        "#un grande aumento del numero di features. Altri encoders potrebbero performare meglio (es: hashing trick).\n",
        "#semplificazione N2: non si considera la struttura gerarchica dei conti ma le labels vengono predette come fossero 13 classi indipendenti\n",
        "#semplificazione N3: si valutano le performance con una semplice divisione train-test senza ricorrere alla CV (sarà poi fatto nel Notebook 2)\n",
        "#semplificazione N4: non si risistemano le stringe del CodiceTipo che potrebbero essere formattate meglio dando vita a meno\n",
        "#classi binarie\n",
        "\n",
        "#N1\n",
        "ModalitaPagamento_encoded = pd.get_dummies(data.ModalitaPagamento, prefix='ModalitaPagamento')\n",
        "print(ModalitaPagamento_encoded.shape)\n",
        "CodiceTipo_encoded = pd.get_dummies(data.CodiceTipo, prefix='CodiceTipo')\n",
        "print(CodiceTipo_encoded.shape)\n",
        "NumeroDDT_encoded = pd.get_dummies(data.NumeroDDT, prefix='NumeroDDT')\n",
        "print(NumeroDDT_encoded.shape)\n",
        "CodiceCedente_encoded = pd.get_dummies(data.CodiceCedente, prefix='CodiceCedente')\n",
        "print(CodiceCedente_encoded.shape)\n",
        "\n",
        "data.drop(['CodiceTipo', 'ModalitaPagamento', 'CodiceCedente', 'NumeroDDT'], axis=1, inplace=True)\n",
        "data = pd.concat(objs=[data, CodiceTipo_encoded, ModalitaPagamento_encoded, CodiceCedente_encoded, NumeroDDT_encoded], axis=1)\n",
        "\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "\n",
        "#si arriva ad avere 203 features, a causa dei One Hot Encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-6-eZDSPAzW",
        "outputId": "92ecad30-fbc1-41c1-c9d0-28da90db52ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5877, 8)\n",
            "(5877, 23)\n",
            "(5877, 109)\n",
            "(5877, 57)\n",
            "(5877, 206)\n",
            "Index(['Descrizione', 'Numero', 'PrezzoUnitario', 'PrezzoTotale',\n",
            "       'AliquotaIVA', 'Conto', 'Year', 'Month', 'Day', 'CodiceTipo_',\n",
            "       ...\n",
            "       'NumeroDDT_PKL.21.1321', 'NumeroDDT_PKL.21.1457',\n",
            "       'NumeroDDT_PKL.21.161', 'NumeroDDT_PKL.21.195', 'NumeroDDT_PKL.21.471',\n",
            "       'NumeroDDT_PKL.21.520', 'NumeroDDT_PKL.21.55', 'NumeroDDT_PKL.21.597',\n",
            "       'NumeroDDT_PKL.21.914', 'NumeroDDT_PKL.21.97'],\n",
            "      dtype='object', length=206)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analisi della distribuzione della variabile target\n",
        "\n",
        "print(data.groupby('Conto').count())\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "jzGdMH30NWMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rimozione delle unità statistiche con target troppo rari (threshold = 5, incluso). La molteplicità dei target scende da 24 a 13.\n",
        "#per farlo si crea un nuovo df per non perdere traccia delle unità statistiche eliminate\n",
        "\n",
        "mask = (data['Conto'] != '18/40/501')&(data['Conto'] != '66/25/505')&(data['Conto'] != '66/25/508')&(data['Conto'] != '66/30/060')&(data['Conto'] != '68/05/005')&(data['Conto'] != '68/05/133')&(data['Conto'] != '68/05/290')&(data['Conto'] != '68/05/320')&(data['Conto'] != '68/05/385')&(data['Conto'] != '68/05/407')&(data['Conto'] != '88/20/035')\n",
        "data2 = data[mask]\n",
        "data2.reset_index(inplace=True)\n",
        "data2 = data2.drop(['index'], axis=1)\n",
        "print(data2)"
      ],
      "metadata": {
        "id": "3cq5NJDvNWRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#in vista del semi supervised learning, separazione dei dati supervisionati e non supervisionati\n",
        "\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "\n",
        "data_labeled = data2[data2['Conto'].notna()]\n",
        "data_unlabeled = data2[data2['Conto'].isnull()]\n",
        "\n",
        "data_labeled.reset_index(inplace=True)\n",
        "data_labeled = data_labeled.drop('index', axis=1)\n",
        "data_unlabeled.reset_index(inplace=True)\n",
        "data_unlabeled = data_unlabeled.drop('index', axis=1)\n",
        "\n",
        "print(data_labeled.shape)\n",
        "print(data_unlabeled.shape)\n",
        "\n",
        "#si usa solo la porzione di dati labeled in un primo train-test di alcuni classificatori"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-sg4UMUkjDA",
        "outputId": "e45d706f-af9f-48b5-b086-19ca46ef2eef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1794, 206)\n",
            "(4061, 206)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#divisione dei dati supervised in train e test set che saranno comuni a tutte le configurazioni e i modelli provati\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "features = data_labeled.drop(['Descrizione', 'Conto', 'Numero'], axis=1)\n",
        "targets = data_labeled.Conto\n",
        "num = data_labeled.Numero\n",
        "descr = data_labeled.Descrizione\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, shuffle=False)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcaHctJG8JlQ",
        "outputId": "9bc7d812-f842-4424-8496-ee7fc8da0af9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1255, 203)\n",
            "(539, 203)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trasformazione della descrizione in features numeriche grazie al metodo Bag-of-Words, implementato grazie alla classe\n",
        "#CountVectorizer di sklearn. Ha più senso costruire il dizionario di parole adesso, dopo aver separato i dati unsupervised,\n",
        "#perchè questi non saranno comunque usati nella procedura di train-test e ampliano solamente la dimensione del dizionario.\n",
        "#Inoltre, per simulare più realisticamente la realtà operativa, il dizionario viene costruito usando solo il training set;\n",
        "#le nuove parole presenti nel test set saranno ignorate.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "descr_train = descr[X_train.index]\n",
        "descr_test = descr[X_test.index]\n",
        "\n",
        "print(descr.head())\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bag_train = vectorizer.fit_transform(list(descr_train))\n",
        "bag_train = pd.DataFrame(bag_train.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "print(bag_train.head(10))\n",
        "print(bag_train.shape)\n",
        "\n",
        "bag_test = vectorizer.transform(list(descr_test))\n",
        "bag_test = pd.DataFrame(bag_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "bag_test.index = X_test.index\n",
        "\n",
        "print(bag_test.head(10))\n",
        "print(bag_test.shape)\n",
        "print(bag_train.index)\n",
        "print(bag_test.index)\n",
        "print(X_train.index)\n",
        "print(X_test.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3CQ92d1Zr5g",
        "outputId": "094c0bad-640c-4114-f8b4-b52d37edcfc1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    A513-77199580-8000500131329-NUTELLA G3000X2 SC...\n",
            "1    CONTRIBUTO CONAI-A513-77199580-8000500131329-N...\n",
            "2             AB3 MISCELA CREMA BAR CONFEZIONE DA Kg.3\n",
            "3                                        /D Lotto V38I\n",
            "4                  N ZUCCHERO SEMOLATO ASTUCCI da Kg.1\n",
            "Name: Descrizione, dtype: object\n",
            "   00  000  000764  000887  000899  000928  002  00217  00222  007694433  ...  \\\n",
            "0   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "1   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "2   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "3   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "4   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "5   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "6   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "7   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "8   0    0       0       0       0       0    1      0      0          0  ...   \n",
            "9   0    0       0       0       0       0    0      0      0          0  ...   \n",
            "\n",
            "   yes  yoga  yogurt  yonkers  zacapa  zenzero  zero  zuccheriera  zucchero  \\\n",
            "0    0     0       0        0       0        0     0            0         0   \n",
            "1    0     0       0        0       0        0     0            0         0   \n",
            "2    0     0       0        0       0        0     0            0         0   \n",
            "3    0     0       0        0       0        0     0            0         0   \n",
            "4    0     0       0        0       0        0     0            0         1   \n",
            "5    0     0       0        0       0        0     0            0         0   \n",
            "6    0     0       0        0       0        0     0            0         0   \n",
            "7    0     0       0        0       0        0     0            0         0   \n",
            "8    0     0       0        0       0        0     0            0         0   \n",
            "9    0     0       0        0       0        0     0            0         0   \n",
            "\n",
            "   zucher  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "5       0  \n",
            "6       0  \n",
            "7       0  \n",
            "8       0  \n",
            "9       0  \n",
            "\n",
            "[10 rows x 1358 columns]\n",
            "(1255, 1358)\n",
            "      00  000  000764  000887  000899  000928  002  00217  00222  007694433  \\\n",
            "1255   0    0       0       0       0       0    0      0      0          0   \n",
            "1256   0    0       0       0       0       0    0      0      0          0   \n",
            "1257   0    0       0       0       0       0    0      0      0          0   \n",
            "1258   0    0       0       0       0       0    0      0      0          0   \n",
            "1259   0    0       0       0       0       0    0      0      0          0   \n",
            "1260   0    0       0       0       0       0    0      0      0          0   \n",
            "1261   0    0       0       0       0       0    0      0      0          0   \n",
            "1262   0    0       0       0       0       0    0      0      0          0   \n",
            "1263   0    0       0       0       0       0    0      0      0          0   \n",
            "1264   0    0       0       0       0       0    0      0      0          0   \n",
            "\n",
            "      ...  yes  yoga  yogurt  yonkers  zacapa  zenzero  zero  zuccheriera  \\\n",
            "1255  ...    0     0       0        0       0        0     0            0   \n",
            "1256  ...    0     0       0        0       0        0     0            0   \n",
            "1257  ...    0     0       0        0       0        0     0            0   \n",
            "1258  ...    0     0       0        0       0        0     0            0   \n",
            "1259  ...    0     0       0        0       0        0     0            0   \n",
            "1260  ...    0     0       0        0       0        0     0            0   \n",
            "1261  ...    0     0       0        0       0        0     0            0   \n",
            "1262  ...    0     0       0        0       0        0     0            0   \n",
            "1263  ...    0     0       0        0       0        0     0            0   \n",
            "1264  ...    0     0       0        0       0        0     0            0   \n",
            "\n",
            "      zucchero  zucher  \n",
            "1255         0       0  \n",
            "1256         1       0  \n",
            "1257         0       0  \n",
            "1258         0       0  \n",
            "1259         0       0  \n",
            "1260         0       0  \n",
            "1261         0       0  \n",
            "1262         0       0  \n",
            "1263         0       0  \n",
            "1264         0       0  \n",
            "\n",
            "[10 rows x 1358 columns]\n",
            "(539, 1358)\n",
            "RangeIndex(start=0, stop=1255, step=1)\n",
            "Int64Index([1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264,\n",
            "            ...\n",
            "            1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793],\n",
            "           dtype='int64', length=539)\n",
            "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
            "            ...\n",
            "            1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254],\n",
            "           dtype='int64', length=1255)\n",
            "Int64Index([1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264,\n",
            "            ...\n",
            "            1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793],\n",
            "           dtype='int64', length=539)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#estensione di X_train e X_test grazie alle nuove features estratte dalla descrizione. Estensione anche del df features,\n",
        "#composto da questi 2, perchè serve per fare feature selection\n",
        "\n",
        "X_train = pd.concat(objs=(X_train, bag_train), axis=1)\n",
        "X_test = pd.concat(objs=(X_test, bag_test), axis=1)\n",
        "features = pd.concat(objs=(X_train, X_test), axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(features.shape)\n",
        "\n",
        "#ora ogni sample ha oltre 1500 feature, la maggior parte delle quali provengono dalla descrizione testuale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeiutYxyf8cI",
        "outputId": "c037a9e2-4733-47c9-dea8-8ea8973324f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1255, 1561)\n",
            "(539, 1561)\n",
            "(1794, 1561)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creazione del dataset totale (con tutte le righe di data) inserendo anche le features provenienti dalla descrizione (il dizionario\n",
        "#comunque è quello creato con le sole righe di training). Questo è il dataset da cui ripartire nel Notebook 2\n",
        "\n",
        "descr_all = data.Descrizione\n",
        "bag_all = vectorizer.transform(list(descr_all))\n",
        "bag_all = pd.DataFrame(bag_all.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "data = pd.concat(objs=(data, bag_all), axis=1)\n",
        "print(data.shape)\n",
        "\n",
        "data.to_excel('/content/df_preprocessed.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQw2mWaIQbUx",
        "outputId": "89c912c8-812b-4601-cde9-46548dd448a9"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5877, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#primo classificatore provato: Naive Bayes, con diverse assunzioni sulla distribuzione delle features condizionata al target. \n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "gnb = BernoulliNB()\n",
        "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        "print(1-((y_test != y_pred).sum()/ X_test.shape[0]))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#accuracy performance: GaussianNB: 0.79, BernoulliNB: 0.83"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHYoMNqZAZxX",
        "outputId": "549f6659-80be-440c-fd0d-6241f4851fa1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7884972170686456\n",
            "[0.61363636 0.66920152 0.8875     0.9057971  0.75       0.\n",
            " 0.         0.         0.85714286 0.98275862 0.        ]\n",
            "0.7884972170686455\n",
            "0.5150942239846089\n",
            "0.7765685183653288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#secondo classificatore provato: Decision Tree\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(max_depth=25)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "#print(clf.feature_importances_)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "#print(f1_score(y_test, y_pred, average='micro')), è inutile tanto è uguale all'accuracy\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#riduzione delle features secondo il criterio di importanza basato sul Gini \n",
        "\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "features_new = model.transform(features)\n",
        "print(features.shape)\n",
        "print(features_new.shape)\n",
        "\n",
        "X_train_new, X_test_new, y_train, y_test = train_test_split(features_new, targets, test_size=0.3, shuffle=False)\n",
        "clf2 = tree.DecisionTreeClassifier(max_depth=25)\n",
        "y_pred2 = clf2.fit(X_train_new, y_train).predict(X_test_new)\n",
        "print(accuracy_score(y_test, y_pred2))\n",
        "#print(clf2.feature_importances_)\n",
        "\n",
        "#le performance sono intorno a 0.93 sia col modello completo che con quello ridotto, che ha circa 50 features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn2brf1CE_xP",
        "outputId": "de8cbfa6-3275-423c-ada8-ca0f53274e69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9257884972170687\n",
            "[0.93495935 0.88505747 0.91358025 0.92366412 1.         1.\n",
            " 0.8        1.         1.         1.         0.33333333]\n",
            "0.8900540475674711\n",
            "0.9296612910951791\n",
            "(1794, 1561)\n",
            "(1794, 49)\n",
            "0.9332096474953617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot colorato del decision tree\n",
        "\n",
        "!pip install graphviz\n",
        "import graphviz\n",
        "import pydotplus\n",
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                                feature_names=features.columns,  \n",
        "                                class_names=targets,\n",
        "                                filled=True)\n",
        "\n",
        "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "pydot_graph.write_png('/content/original_tree.png')\n",
        "pydot_graph.set_size('\"5,5!\"')\n",
        "pydot_graph.write_png('/content/resized_tree.png')\n",
        "pydot_graph\n",
        "# Draw graph\n",
        "#graph = graphviz.Source(dot_data, format=\"png\") \n",
        "#graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU0d7utkFEzu",
        "outputId": "6edc21f6-0a51-4ad4-9917-813af5e04661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pydotplus.graphviz.Dot at 0x7f9640e9b550>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#terzo classificatore provato: Random Forest\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "features.PrezzoUnitario = scaler.fit_transform(np.array(features.PrezzoUnitario).reshape(-1, 1))\n",
        "features.PrezzoTotale = scaler.fit_transform(np.array(features.PrezzoTotale).reshape(-1, 1))\n",
        "features.AliquotaIVA = scaler.fit_transform(np.array(features.AliquotaIVA).reshape(-1, 1))\n",
        "features.Year = scaler.fit_transform(np.array(features.Year).reshape(-1, 1))\n",
        "features.Month = scaler.fit_transform(np.array(features.Month).reshape(-1, 1))\n",
        "features.Day = scaler.fit_transform(np.array(features.Day).reshape(-1, 1))\n",
        "features.Similarity_Materie_Prime = scaler.fit_transform(np.array(features.Similarity_Materie_Prime).reshape(-1, 1))\n",
        "features.Similarity_Materie_Consumo = scaler.fit_transform(np.array(features.Similarity_Materie_Consumo).reshape(-1, 1))\n",
        "features.Similarity_Merci = scaler.fit_transform(np.array(features.Similarity_Merci).reshape(-1, 1))\n",
        "features.Similarity_Merci_Prodotti = scaler.fit_transform(np.array(features.Similarity_Merci_Prodotti).reshape(-1, 1))\n",
        "\n",
        "X_train = features.loc[540:,]\n",
        "X_test = features.loc[:539,]\n",
        "y_train = targets.loc[540:,]\n",
        "y_test = targets.loc[:539,]\n",
        "\"\"\"\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=30, bootstrap = False)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "#print(clf.feature_importances_)\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "#print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\"\"\"\n",
        "\n",
        "#feature selection\n",
        "\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "features_new = pd.DataFrame(model.transform(features))\n",
        "print(features_new.shape)\n",
        "\n",
        "X_train_new, X_test_new, y_train, y_test = train_test_split(features_new, targets, test_size=0.3, shuffle=False)\n",
        "clf2 = RandomForestClassifier(n_estimators=100, max_depth=50, bootstrap = False)\n",
        "y_pred2 = clf2.fit(X_train_new, y_train).predict(X_test_new)\n",
        "print(accuracy_score(y_test, y_pred2))\n",
        "\n",
        "#le performance, in quanto ad accuracy, sono paragonabili tra il modello con con tutte le features e quello ridotto e intorno \n",
        "#a 0.94/0.95. E' stata testata anche una pipeline che prevede prima una standardizzazione dei dati ma senza riportare\n",
        "#significative variazioni nella performance. Anche F-score assume più o meno gli stessi valori (nella versione weighted che tiene\n",
        "#conto della dimensione delle classi). Invece la versione macro è potenzialmente anche più alta dell'accuracy perchè, come si \n",
        "#vede dalla confusion matrix, gli errori sono di solito sulle classe più grandi; a volte però si abbassa quando non viene appresa la classe\n",
        "#66/25/509, che ha poche istanze, e quindi il suo F score è 0.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEelxyZ9TRbg",
        "outputId": "d3b1ed5f-488b-4fca-85e9-997d39e87188"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9517625231910947\n",
            "(1794, 142)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9443413729128015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#salvataggio del modello RF fittato sui dati supervised di test finora disponibili così da poterlo usare nel Notebook 2\n",
        "\n",
        "import pickle\n",
        "\n",
        "#clf = RandomForestClassifier(n_estimators=100, max_depth=30, bootstrap = False)\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "filename = '/content/finalized_model.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))\n",
        "\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEgJ95qgDOet",
        "outputId": "676b1d5e-dd48-4184-8bd4-7a6d5c199325"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9517625231910947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature selection basata sul random forest, basata sulle features scelte inizialmente\n",
        "\n",
        "mask = clf.feature_importances_ > 0.01\n",
        "print(features.columns[mask])\n",
        "\n",
        "#Risultano importanti il prezzo unitario, l'IVA, il giorno (???), la modalità di pagamento, il codice tipo e il codice cedente\n",
        "#Risultano poco importanti il prezzo totale, il mese, il numero DDT e alcune features estratte dalla descrizione. Vuol dire che \n",
        "#non hanno una grande influenza sulle performance ma comunque aiutano un po' il modello.\n",
        "#Risultano non importanti il codice cessionario, il tipo di documento, la condizione di pagamento e l'anno. In effetti queste features assumono sempre (o quasi)\n",
        "#lo stesso valore in questo dataset (eliminate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zfOtMFv9ibB",
        "outputId": "e5c04a2c-2da7-4958-b32f-06a4fe74a5a2"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PrezzoUnitario', 'PrezzoTotale', 'AliquotaIVA', 'Month', 'Day',\n",
            "       'CodiceTipo_', 'CodiceTipo_AswArtFor', 'CodiceTipo_Codice',\n",
            "       'CodiceTipo_Codice articolo fornitore', 'CodiceTipo_EAN',\n",
            "       'ModalitaPagamento_', 'ModalitaPagamento_MP01',\n",
            "       'ModalitaPagamento_MP02', 'ModalitaPagamento_MP05',\n",
            "       'ModalitaPagamento_MP19', 'CodiceCedente_10483110010',\n",
            "       'CodiceCedente_183410653', 'CodiceCedente_4352551214',\n",
            "       'CodiceCedente_6909241215', 'CodiceCedente_7581111213',\n",
            "       'CodiceCedente_777280157', 'CodiceCedente_9407411215', 'NumeroDDT_',\n",
            "       'NumeroDDT_0848053410', 'it', 'litro', 'mat', 'spese', 'varie'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quarto classificatore provato: AdaBoost\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "clf = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=8), n_estimators=100)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\"\"\"\n",
        "\n",
        "#accuracy intorno a 0.94/0.95, come RF, però non funziona la feature selection.\n",
        "#Osservazione: l'accuracy sale fino a 0.96/0.97 se la dimensione del training viene aumentata (90% dei dati) a scapito di quella del test set, cosa che \n",
        "#non accade nel RF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "VLjjVHQTJzTG",
        "outputId": "3e0cefc0-9e92-4392-b125-3a9c1ffdf191"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9443413729128015\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.metrics import f1_score\\nprint(f1_score(y_test, y_pred, average=None))\\nprint(f1_score(y_test, y_pred, average='micro'))\\nprint(f1_score(y_test, y_pred, average='macro'))\\nprint(f1_score(y_test, y_pred, average='weighted'))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quinto classificatore provato: SVC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "features = data_labeled.drop(['Conto'], axis=1)\n",
        "\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "features.PrezzoUnitario = scaler.fit_transform(np.array(features.PrezzoUnitario).reshape(-1, 1))\n",
        "features.PrezzoTotale = scaler.fit_transform(np.array(features.PrezzoTotale).reshape(-1, 1))\n",
        "features.AliquotaIVA = scaler.fit_transform(np.array(features.AliquotaIVA).reshape(-1, 1))\n",
        "features.Year = scaler.fit_transform(np.array(features.Year).reshape(-1, 1))\n",
        "features.Month = scaler.fit_transform(np.array(features.Month).reshape(-1, 1))\n",
        "features.Day = scaler.fit_transform(np.array(features.Day).reshape(-1, 1))\n",
        "\"\"\"\n",
        "\n",
        "print(features.columns)\n",
        "targets = data_labeled.Conto\n",
        "#print(features.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, shuffle=False)\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='scale'))\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#performance intorno a 0.87, anche al variare di alcuni parametri come il coefficiente di regolarizzazione C e gamma.\n",
        "#Non cambia praticamente niente se si normalizzano tutte le feature o solo quelle numeriche.\n",
        "#Nei 2 modelli migliori (AdaBoost e RF) l'accuracy e F score sono allineati, nei modelli peggiori come appunto SVC, F score\n",
        "#in modalità macro risente del fatto che alcune classi non vengono apprese e perciò hanno F score individuale uguale a 0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHBpvpUi4yTU",
        "outputId": "aa0b41e8-1ad7-4f12-fbbe-8d9a8f8b90dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PrezzoUnitario', 'PrezzoTotale', 'AliquotaIVA',\n",
            "       'Similarity_Materie_Prime', 'Similarity_Materie_Consumo',\n",
            "       'Similarity_Merci', 'Similarity_Merci_Prodotti', 'Year', 'Month', 'Day',\n",
            "       ...\n",
            "       'NumeroDDT_PKL.21.1321', 'NumeroDDT_PKL.21.1457',\n",
            "       'NumeroDDT_PKL.21.161', 'NumeroDDT_PKL.21.195', 'NumeroDDT_PKL.21.471',\n",
            "       'NumeroDDT_PKL.21.520', 'NumeroDDT_PKL.21.55', 'NumeroDDT_PKL.21.597',\n",
            "       'NumeroDDT_PKL.21.914', 'NumeroDDT_PKL.21.97'],\n",
            "      dtype='object', length=204)\n",
            "0.8534322820037106\n",
            "[0.87826087 0.88297872 0.9044586  0.81506849 0.         0.\n",
            " 0.         1.         0.82758621 0.99130435 1.        ]\n",
            "0.8534322820037106\n",
            "0.6636052035971737\n",
            "0.8332993756936149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo di quali classi sono presenti nel train set, nel test set e quali vengono effettivamente predette\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(np.unique(y_train))\n",
        "print(np.unique(y_test))\n",
        "print(np.unique(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flBtA9Qqdsqu",
        "outputId": "4056355c-9c43-4d92-b0fe-38bf85c53148"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['66/05/006' '66/20/005' '66/25/005' '66/25/006' '66/25/506' '66/25/507'\n",
            " '66/25/509' '66/30/015' '66/30/017' '66/30/055' '68/05/025' '68/05/490'\n",
            " '70/05/101']\n",
            "['66/05/006' '66/20/005' '66/25/005' '66/25/006' '66/25/506' '66/25/509'\n",
            " '66/30/015' '66/30/017' '66/30/055' '68/05/025' '68/05/490']\n",
            "['66/05/006' '66/20/005' '66/25/005' '66/25/006' '66/25/506' '66/25/507'\n",
            " '66/25/509' '66/30/015' '66/30/017' '66/30/055' '68/05/025' '68/05/490']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo della numerosità delle varie classi nei set\n",
        "res = {}\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "for i,j in zip(unique, counts):\n",
        "  res[i] = {'train' : j}\n",
        "\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "for i,j in zip(unique, counts):\n",
        "  res[i]['test'] = j\n",
        "\n",
        "unique, counts = np.unique(y_pred, return_counts=True)\n",
        "for i,j in zip(unique, counts):\n",
        "  res[i]['pred'] = j\n",
        "\n",
        "for k,v in res.items():\n",
        "  print(k,v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ran3tMR4lKPg",
        "outputId": "59704158-3ec3-4b07-be7e-ce14ed905193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66/05/006 {'train': 256, 'test': 121, 'pred': 121}\n",
            "66/20/005 {'train': 166, 'test': 89, 'pred': 90}\n",
            "66/25/005 {'train': 200, 'test': 86, 'pred': 74}\n",
            "66/25/006 {'train': 285, 'test': 129, 'pred': 142}\n",
            "66/25/506 {'train': 14, 'test': 20, 'pred': 20}\n",
            "66/25/507 {'train': 13}\n",
            "66/25/509 {'train': 6, 'test': 2, 'pred': 2}\n",
            "66/30/015 {'train': 17, 'test': 6, 'pred': 4}\n",
            "66/30/017 {'train': 5, 'test': 3, 'pred': 3}\n",
            "66/30/055 {'train': 39, 'test': 24, 'pred': 24}\n",
            "68/05/025 {'train': 236, 'test': 57, 'pred': 57}\n",
            "68/05/490 {'train': 6, 'test': 2, 'pred': 2}\n",
            "70/05/101 {'train': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix per analisi degli errori piu comuni\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
        "\n",
        "#con l'aggiunta delle informazioni estratte dalla descrizione le performance migliorano ma gli errori restano relativi alle stesse\n",
        "#categorie di prima, in misura minore. Fortunatamente queste features aggiuntive non creano ocnfusione nelle altre classi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iCowoHVoGqA",
        "outputId": "e47fe278-0418-462c-e2ac-36d6b81bec84"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'66/05/006': 121, '66/20/005': 89, '66/25/005': 86, '66/25/006': 129, '66/25/506': 20, '66/25/509': 2, '66/30/015': 6, '66/30/017': 3, '66/30/055': 24, '68/05/025': 57, '68/05/490': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[118,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  6,  82,   0,   1,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,  76,  10,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   3, 125,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,  20,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0],\n",
              "       [  0,   2,   0,   0,   0,   0,   4,   0,   0,   0,   0],\n",
              "       [  0,   1,   0,   0,   0,   0,   0,   2,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  24,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  57,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2]])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ora creo il dataset per il semi supervised training con le 1255 unità non usate per il test e tutte quelle con 'Conto' NaN.\n",
        "#Inoltre viene performato l'encoding delle labels per non avere stringhe e -1 ma solo interi\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(data_labeled['Conto'])\n",
        "data_labeled['Conto'] = le.transform(data_labeled['Conto'])\n",
        "data_semi = pd.concat(objs=[data_train, data_unlabeled])\n",
        "data_semi.reset_index(inplace=True)\n",
        "data_semi = data_semi.drop('index', axis=1)\n",
        "data_semi = data_semi.fillna(-1)\n",
        "print(data_semi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIE3eju-7q3v",
        "outputId": "ecf2577e-2a0e-4fb7-894f-401c78f31157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      PrezzoUnitario  PrezzoTotale  ...  NumeroDDT_PKL.21.97  Conto\n",
            "0             17.980        308.16  ...                    0      2\n",
            "1              0.053          1.06  ...                    0      2\n",
            "2             19.000        369.36  ...                    0      3\n",
            "3              0.000          0.00  ...                    0      3\n",
            "4              1.350         27.00  ...                    0      3\n",
            "...              ...           ...  ...                  ...    ...\n",
            "5311           0.000          0.00  ...                    0     -1\n",
            "5312           0.000          0.00  ...                    0     -1\n",
            "5313           0.000          0.00  ...                    0     -1\n",
            "5314           0.000          0.00  ...                    0     -1\n",
            "5315          10.000         10.00  ...                    0     -1\n",
            "\n",
            "[5316 rows x 205 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#QUESTE ULTIME 4 CELLE SONO MANTENUTE SOLO IN CASO IN CUI SERVISSE RIUSARE ALCUNE PARTI DI CODICE MA IN REALTA' LO PSEUDO-LABELING\n",
        "#E' IMPLEMENTATO DIVERSAMENTE NEL NOTEBOOK 2\n",
        "\n",
        "#ora il dataset data_semi è pronto per il semi supervised learning dato che ha dei -1 al posto dei target mancanti\n",
        "\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#clf = make_pipeline(StandardScaler(), SVC(gamma='scale', probability=True))\n",
        "#clf = tree.DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)\n",
        "clf = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=8), n_estimators=100)\n",
        "calibrated_clf = CalibratedClassifierCV(base_estimator=clf)\n",
        "\n",
        "X = data_semi.drop('Conto', axis=1)\n",
        "y = data_semi.Conto\n",
        "calibrated_clf.fit(X, y)\n",
        "\n",
        "self_training_model = SelfTrainingClassifier(calibrated_clf, threshold=0.95, max_iter=2)\n",
        "self_training_model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwzgHwT7mkK2",
        "outputId": "2f9c5312-d27e-4704-d3ab-5cb648ede903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelfTrainingClassifier(base_estimator=CalibratedClassifierCV(base_estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=8),\n",
              "                                                                                               n_estimators=100)),\n",
              "                       max_iter=2, threshold=0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo di quali samples sono stati labeled e a che iterazione\n",
        "\n",
        "for i in range(len(self_training_model.labeled_iter_)):\n",
        "  print(self_training_model.labeled_iter_[i])\n",
        "  print(self_training_model.transduction_[i])\n"
      ],
      "metadata": {
        "id": "SgLxUPBMCmnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creazione del nuovo training set con l'aggiunta dei nuovi dati pseudo supervisionati\n",
        "\n",
        "mask = self_training_model.labeled_iter_ != -1\n",
        "data_train = data_semi.loc[mask,]\n",
        "data_train.Conto = self_training_model.transduction_[mask]\n",
        "print(data_train)"
      ],
      "metadata": {
        "id": "7q-GLd2uFVPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo delle performance predittive grazie all'aumento dei samples supervisionati, usando lo stesso test set\n",
        "#del caso senza semi supervised learning\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(self_training_model.predict(data_test.drop('Conto', axis=1)), le.transform(data_test.Conto)))\n",
        "\n",
        "#purtroppo le performance non migliorano come sperato a prescindere da quanto venga ampliato il training set grazie alle pseudo labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBSHWzE0rsgu",
        "outputId": "0f02860a-6a5d-402b-dac4-20e24040b852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9461966604823747\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PrimeOffice.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JSZlS9QUNdf"
      },
      "outputs": [],
      "source": [
        "#NOTEBOOK 1: data cleaning, feature selection e fitting di modelli di classificazione, con analisi delle performance e degli errori commessi.\n",
        "#Le prime 2 celle sono dedicate a settare la rete Word2Vec in italiano che serve a estrarre features semantiche\n",
        "#dalle descrizioni delle fatture in modo da distinguere meglio le classi\n",
        "\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "%cd fastText\n",
        "!sudo pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWNy2R-5UNo2",
        "outputId": "649fa520-6e3f-4035-9b47-b14edd4dac00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.bin.gz\n",
            "\n",
            "300\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "fasttext.util.download_model('it', if_exists='ignore')\n",
        "ft = fasttext.load_model('cc.it.300.bin')\n",
        "print(ft.get_dimension())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-qYyUrenIc5",
        "outputId": "453cf46b-749f-45ae-b3e6-33225b7f9b80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lettura delle descrizioni dal dataset\n",
        "\n",
        "from scipy import spatial\n",
        "import pandas as pd\n",
        "!pip install --upgrade openpyxl\n",
        "\n",
        "descr = pd.read_excel('/content/drive/MyDrive/df_final.xlsx')\n",
        "descr = descr['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_Descrizione']\n",
        "\n",
        "print(list(descr))"
      ],
      "metadata": {
        "id": "X_vUrOdoKZxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adesso, per ogni descrizione, si devono assegnare 4 feature di presumibile appartenenza alle 4 classi critiche. Per\n",
        "#ciascuna classe vengono selezionate 2 parole semanticamente simili ai prodotti classificati in tale classe e viene valutata,\n",
        "#grazie all'embedding fornito da Word2Vec, la similarità semantica delle varie parole presenti in una descrizione con queste\n",
        "#2 parole di riferimento, per tutte e 4 le classi. Per ogni descrizione viene poi tenuto solo lo score più alto ottenuto dalle sue parole per individuare\n",
        "#quella chiave\n",
        "\n",
        "similarity_materie_prime = []\n",
        "similarity_materie_consumo = []\n",
        "similarity_merci = []\n",
        "similarity_merci_prodotti = []\n",
        "\n",
        "vector_formaggio = ft.get_word_vector('formaggio')\n",
        "vector_uova = ft.get_word_vector('uova')\n",
        "vector_busta = ft.get_word_vector('busta')\n",
        "vector_posate = ft.get_word_vector('posate')\n",
        "vector_kinder = ft.get_word_vector('kinder')\n",
        "vector_caramella = ft.get_word_vector('caramella')\n",
        "vector_bibita = ft.get_word_vector('bibita')\n",
        "vector_vodka = ft.get_word_vector('vodka')\n",
        "\n",
        "for s in list(descr):\n",
        "  s = s.lower()\n",
        "  s_words = s.split(\" \")\n",
        "\n",
        "  words_similarities_materie_prime = []\n",
        "  words_similarities_materie_consumo = []\n",
        "  words_similarities_merci = []\n",
        "  words_similarities_merci_prodotti = []\n",
        "\n",
        "  for i in s_words:\n",
        "    vector_i = ft.get_word_vector(i)\n",
        "    score_materie_prime = ((1 - spatial.distance.cosine(vector_i, vector_formaggio)) + (1 - spatial.distance.cosine(vector_i, vector_uova)))/2\n",
        "    score_materie_consumo = ((1 - spatial.distance.cosine(vector_i, vector_busta)) + (1 - spatial.distance.cosine(vector_i, vector_posate)))/2\n",
        "    score_merci = ((1 - spatial.distance.cosine(vector_i, vector_kinder)) + (1 - spatial.distance.cosine(vector_i, vector_caramella)))/2\n",
        "    score_merci_prodotti = ((1 - spatial.distance.cosine(vector_i, vector_bibita)) + (1 - spatial.distance.cosine(vector_i, vector_vodka)))/2\n",
        "\n",
        "    words_similarities_materie_prime.append(score_materie_prime)\n",
        "    words_similarities_materie_consumo.append(score_materie_consumo)\n",
        "    words_similarities_merci.append(score_merci)\n",
        "    words_similarities_merci_prodotti.append(score_merci_prodotti)\n",
        "\n",
        "  words_similarities_materie_prime = [x for x in words_similarities_materie_prime if pd.notnull(x)]\n",
        "  words_similarities_materie_consumo = [x for x in words_similarities_materie_consumo if pd.notnull(x)]\n",
        "  words_similarities_merci = [x for x in words_similarities_merci if pd.notnull(x)]\n",
        "  words_similarities_merci_prodotti = [x for x in words_similarities_merci_prodotti if pd.notnull(x)]\n",
        "\n",
        "  best_materie_prime = max(words_similarities_materie_prime)\n",
        "  best_materie_consumo = max(words_similarities_materie_consumo)\n",
        "  best_merci = max(words_similarities_merci)\n",
        "  best_merci_prodotti = max(words_similarities_merci_prodotti)\n",
        "\n",
        "  similarity_materie_prime.append(best_materie_prime)\n",
        "  similarity_materie_consumo.append(best_materie_consumo)\n",
        "  similarity_merci.append(best_merci)\n",
        "  similarity_merci_prodotti.append(best_merci_prodotti)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dlQKwMp8WMT",
        "outputId": "8337e8f5-5a23-4084-f016-797fe1de7de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDJeckHKZ0Ui"
      },
      "outputs": [],
      "source": [
        "#lettura del file excel in pandas\n",
        "\n",
        "import pandas as pd\n",
        "!pip install --upgrade openpyxl\n",
        "\n",
        "data = pd.read_excel('/content/drive/MyDrive/df_final.xlsx')\n",
        "data = data.drop('Unnamed: 0', axis=1)\n",
        "print(data.head(5))\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selezione delle colonne di interesse\n",
        "\n",
        "data = data[['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale',\n",
        "            'FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA',\n",
        "            'FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT',\n",
        "            'Conto']]\n",
        "\n",
        "print(data.shape)\n",
        "print(data.head(5))"
      ],
      "metadata": {
        "id": "Yz1pj_kKJ7NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aggiunta delle colonne con le informazioni estratte dalla descrizione precedentemente create\n",
        "\n",
        "data = pd.concat(objs=[data, descr.rename('Descrizione'), pd.Series(similarity_materie_prime).rename('Similarity_Materie_Prime'), pd.Series(similarity_materie_consumo).rename('Similarity_Materie_Consumo'), pd.Series(similarity_merci).rename('Similarity_Merci'), pd.Series(similarity_merci_prodotti).rename('Similarity_Merci_Prodotti')], axis=1)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "yMmB-gAdiPn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo del tipo delle colonne\n",
        "\n",
        "for column in data.columns:\n",
        "  print(column)\n",
        "  print(type(data[column][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0wSiUuvJ7Qu",
        "outputId": "fb69c332-32c1-4831-e068-96553df2a0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero\n",
            "<class 'str'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first\n",
            "<class 'str'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario\n",
            "<class 'numpy.float64'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale\n",
            "<class 'numpy.float64'>\n",
            "FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first\n",
            "<class 'str'>\n",
            "FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA\n",
            "<class 'numpy.float64'>\n",
            "FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice\n",
            "<class 'numpy.int64'>\n",
            "FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data\n",
            "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
            "FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT\n",
            "<class 'str'>\n",
            "Conto\n",
            "<class 'str'>\n",
            "Descrizione\n",
            "<class 'str'>\n",
            "Similarity_Materie_Prime\n",
            "<class 'numpy.float64'>\n",
            "Similarity_Materie_Consumo\n",
            "<class 'numpy.float64'>\n",
            "Similarity_Merci\n",
            "<class 'numpy.float64'>\n",
            "Similarity_Merci_Prodotti\n",
            "<class 'numpy.float64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conversione del tipo di dato in alcune colonne\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "data['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA'] = data['FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA'].astype(int)\n",
        "data['FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice'] = data['FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice'].astype(str)\n"
      ],
      "metadata": {
        "id": "usEqzUHiJ7Tq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conversione della data in 3 colonne giorno-mese-anno per renderle feature adatte a fare machine learning\n",
        "\n",
        "year = pd.Series(pd.DatetimeIndex(data['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data']).year)\n",
        "month = pd.Series(pd.DatetimeIndex(data['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data']).month)\n",
        "day = pd.Series(pd.DatetimeIndex(data['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data']).day)\n",
        "\n",
        "frame = {'year': year, 'month': month, 'day': day}\n",
        "data2 = pd.DataFrame(frame)\n",
        "  \n",
        "data = pd.concat(objs=[data, data2], axis=1)\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9v-rbLHwUCl",
        "outputId": "96257560-1095-467c-f15c-a46c1fe0d548"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale',\n",
            "       'FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA',\n",
            "       'FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice',\n",
            "       'FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data',\n",
            "       'FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT', 'Conto',\n",
            "       'year', 'month', 'day'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminazione della colonna con la data in formato timestamp\n",
        "\n",
        "data.drop('FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Data', axis=1, inplace=True)\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G7mGgsk7GMB",
        "outputId": "bc20b655-a6f3-447c-a5e9-a40540db528b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale',\n",
            "       'FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first',\n",
            "       'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA',\n",
            "       'FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice',\n",
            "       'FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT', 'Conto',\n",
            "       'year', 'month', 'day'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rinominazione delle colonne\n",
        "\n",
        "data = data.rename(columns={'FatturaElettronicaBody_DatiGenerali_DatiGeneraliDocumento_Numero': 'Numero',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_CodiceArticolo_CodiceTipo_first': 'CodiceTipo',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoUnitario': 'PrezzoUnitario',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_PrezzoTotale': 'PrezzoTotale',\n",
        "            'FatturaElettronicaBody_DatiPagamento_DettaglioPagamento_ModalitaPagamento_first': 'ModalitaPagamento',\n",
        "            'FatturaElettronicaBody_DatiBeniServizi_DettaglioLinee_AliquotaIVA': 'AliquotaIVA',\n",
        "            'FatturaElettronicaHeader_CedentePrestatore_DatiAnagrafici_IdFiscaleIVA_IdCodice': 'CodiceCedente',\n",
        "            'FatturaElettronicaBody_DatiGenerali_DatiDDT_NumeroDDT': 'NumeroDDT',\n",
        "            'Conto': 'Conto', 'year': 'Year', 'month': 'Month', 'day': 'Day'})\n",
        "\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGGSzrSmEA6H",
        "outputId": "145cae1f-9a72-474c-fb3b-44dc41f9df10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Numero', 'CodiceTipo', 'PrezzoUnitario', 'PrezzoTotale',\n",
            "       'ModalitaPagamento', 'AliquotaIVA', 'CodiceCedente', 'NumeroDDT',\n",
            "       'Conto', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminazione, in tutte le colonne tranne 'Conto', dei nan che compaiono come float a favore di stringhe vuote (perche tutte le colonne di feature con dei nan sono in formato stringa)\n",
        "Conti = data.Conto\n",
        "data = data.fillna('')\n",
        "data.Conto = Conti\n",
        "print(data.isnull().sum().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40nyRgdM5Bm1",
        "outputId": "c13be900-6744-4ce4-ae4e-332c2cb886ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analisi della distribuzione della variabile target\n",
        "\n",
        "print(data.groupby('Conto').count())\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "UELTR8EALGAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rimozione delle unità statistiche con target troppo rari (threshold = 5, incluso). La molteplicità dei target scende da 24 a 13.\n",
        "\n",
        "mask = (data['Conto'] != '18/40/501')&(data['Conto'] != '66/25/505')&(data['Conto'] != '66/25/508')&(data['Conto'] != '66/30/060')&(data['Conto'] != '68/05/005')&(data['Conto'] != '68/05/133')&(data['Conto'] != '68/05/290')&(data['Conto'] != '68/05/320')&(data['Conto'] != '68/05/385')&(data['Conto'] != '68/05/407')&(data['Conto'] != '88/20/035')\n",
        "data = data[mask]\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "unt1iY8HM4gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b01caed-e54d-4cc9-f72e-ff0285e3f5f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5855, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#semplificazione N1: tutte le features categoriche vengono gestite col semplice One Hot Encoding, anche se questo causa\n",
        "#un grande aumento del numero di features. Altri encoders potrebbero performare meglio (es: hashing trick).\n",
        "#semplificazione N2: non si considera la struttura gerarchica dei conti ma le labels vengono predette come fossero 13 classi indipendenti\n",
        "#semplificazione N3: si utilizza un solo modello predittivo anzichè dividere inizialmente il dataset e usare un modello su \n",
        "#ogni porzione. Ad esempio, potrebbe essere interessante dividere il dataset a seconda dell'aliquota IVA dato che questa\n",
        "#discerne quasi perfettamente le classi 66/05/006 e 66/20/005, sulle quali continuano a essere commessi errori\n",
        "#semplificazione N4: si valutano le performance con una semplice divisione train-test senza ricorrere alla CV\n",
        "#semplificazione N5: non si risistemano le stringe del CodiceTipo che potrebbero essere formattate meglio dando vita a meno\n",
        "#classi binarie\n",
        "\n",
        "#N1\n",
        "ModalitaPagamento_encoded = pd.get_dummies(data.ModalitaPagamento, prefix='ModalitaPagamento')\n",
        "print(ModalitaPagamento_encoded.shape)\n",
        "CodiceTipo_encoded = pd.get_dummies(data.CodiceTipo, prefix='CodiceTipo')\n",
        "print(CodiceTipo_encoded.shape)\n",
        "NumeroDDT_encoded = pd.get_dummies(data.NumeroDDT, prefix='NumeroDDT')\n",
        "print(NumeroDDT_encoded.shape)\n",
        "CodiceCedente_encoded = pd.get_dummies(data.CodiceCedente, prefix='CodiceCedente')\n",
        "print(CodiceCedente_encoded.shape)\n",
        "\n",
        "data.drop(['CodiceTipo', 'ModalitaPagamento', 'CodiceCedente', 'NumeroDDT'], axis=1, inplace=True)\n",
        "data = pd.concat(objs=[data, CodiceTipo_encoded, ModalitaPagamento_encoded, CodiceCedente_encoded, NumeroDDT_encoded], axis=1)\n",
        "\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "\n",
        "#si arriva ad avere 204 features, a causa dei One Hot Encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-6-eZDSPAzW",
        "outputId": "1ffc70a8-07b5-4d43-d585-63de0ef4eb16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5855, 8)\n",
            "(5855, 22)\n",
            "(5855, 109)\n",
            "(5855, 55)\n",
            "(5855, 202)\n",
            "Index(['Numero', 'PrezzoUnitario', 'PrezzoTotale', 'AliquotaIVA', 'Conto',\n",
            "       'Year', 'Month', 'Day', 'CodiceTipo_', 'CodiceTipo_ARTICOLO',\n",
            "       ...\n",
            "       'NumeroDDT_PKL.21.1321', 'NumeroDDT_PKL.21.1457',\n",
            "       'NumeroDDT_PKL.21.161', 'NumeroDDT_PKL.21.195', 'NumeroDDT_PKL.21.471',\n",
            "       'NumeroDDT_PKL.21.520', 'NumeroDDT_PKL.21.55', 'NumeroDDT_PKL.21.597',\n",
            "       'NumeroDDT_PKL.21.914', 'NumeroDDT_PKL.21.97'],\n",
            "      dtype='object', length=202)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#riallocazione della colonna di target come ultima\n",
        "\n",
        "temp = data.Conto\n",
        "data.drop('Conto', axis=1, inplace=True)\n",
        "data = pd.concat(objs=[data, temp], axis=1)\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSi_D--L9NVT",
        "outputId": "ed3ae4bf-8853-4d73-cd85-facbeaaf9481"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Numero', 'PrezzoUnitario', 'PrezzoTotale', 'AliquotaIVA', 'Year',\n",
            "       'Month', 'Day', 'CodiceTipo_', 'CodiceTipo_ARTICOLO',\n",
            "       'CodiceTipo_Articolo',\n",
            "       ...\n",
            "       'NumeroDDT_PKL.21.1457', 'NumeroDDT_PKL.21.161', 'NumeroDDT_PKL.21.195',\n",
            "       'NumeroDDT_PKL.21.471', 'NumeroDDT_PKL.21.520', 'NumeroDDT_PKL.21.55',\n",
            "       'NumeroDDT_PKL.21.597', 'NumeroDDT_PKL.21.914', 'NumeroDDT_PKL.21.97',\n",
            "       'Conto'],\n",
            "      dtype='object', length=202)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#in vista del semi supervised learning, separazione dei dati supervisionati e non supervisionati\n",
        "\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "\n",
        "data_labeled = data[data['Conto'].notna()]\n",
        "data_unlabeled = data[data['Conto'].isnull()]\n",
        "\n",
        "data_labeled.reset_index(inplace=True)\n",
        "data_labeled = data_labeled.drop('index', axis=1)\n",
        "data_unlabeled.reset_index(inplace=True)\n",
        "data_unlabeled = data_unlabeled.drop('index', axis=1)\n",
        "\n",
        "print(data_labeled)\n",
        "print(data_unlabeled)\n",
        "\n",
        "#si usa solo la porzione di dati labeled in un primo train-test di alcuni classificatori"
      ],
      "metadata": {
        "id": "A-sg4UMUkjDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#primo classificatore provato: Naive Bayes, con diverse assunzioni sulla distribuzione delle features condizionata al target. \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "features = data_labeled.drop(['Conto'], axis=1)\n",
        "targets = data_labeled.Conto\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, shuffle=False)\n",
        "gnb = CategoricalNB()\n",
        "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        "print(1-((y_test != y_pred).sum()/ X_test.shape[0]))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#accuracy performance: GaussianNB: 0.79, BernoulliNB: 0.83"
      ],
      "metadata": {
        "id": "IHYoMNqZAZxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#secondo classificatore provato: Decision Tree\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "features = data_labeled.drop(['Conto', 'Descrizione', 'Numero'], axis=1)\n",
        "targets = data_labeled.Conto\n",
        "print(features.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, shuffle=False)\n",
        "clf = tree.DecisionTreeClassifier(max_depth=28)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(1-((y_test != y_pred).sum()/ X_test.shape[0]))\n",
        "#print(clf.feature_importances_)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "#print(f1_score(y_test, y_pred, average='micro')), è inutile tanto è uguale all'accuracy\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#riduzione delle features secondo il criterio di importanza basato sul Gini index. Con la soglia scelta di default\n",
        "#si scende di solito a 26 features\n",
        "\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "features_new = model.transform(features)\n",
        "print(features_new.shape)\n",
        "\n",
        "X_train_new, X_test_new, y_train, y_test = train_test_split(features_new, targets, test_size=0.3, shuffle=False)\n",
        "clf2 = tree.DecisionTreeClassifier(max_depth=15)\n",
        "y_pred2 = clf2.fit(X_train_new, y_train).predict(X_test_new)\n",
        "print(1-((y_test != y_pred2).sum()/ X_test_new.shape[0]))\n",
        "#print(clf2.feature_importances_)\n",
        "\n",
        "#le performance scendono leggermente da circa 0.93 a 0.91"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn2brf1CE_xP",
        "outputId": "c2270af4-872d-4dd2-c298-3857d487e24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1794, 204)\n",
            "0.9239332096474954\n",
            "[0.93548387 0.93714286 0.87804878 0.9        0.97435897 0.66666667\n",
            " 0.72727273 1.         0.94117647 1.         1.        ]\n",
            "0.905468213407728\n",
            "0.9239032324174937\n",
            "(1794, 25)\n",
            "0.9202226345083488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmZoX0tbJ6qc",
        "outputId": "11cea5ff-21c8-4fad-fdf0-509bf7595210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "import pydotplus\n",
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                                feature_names=features.columns,  \n",
        "                                class_names=targets,\n",
        "                                filled=True)\n",
        "\n",
        "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "pydot_graph.write_png('/content/original_tree.png')\n",
        "pydot_graph.set_size('\"5,5!\"')\n",
        "pydot_graph.write_png('/content/resized_tree.png')\n",
        "pydot_graph\n",
        "# Draw graph\n",
        "#graph = graphviz.Source(dot_data, format=\"png\") \n",
        "#graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU0d7utkFEzu",
        "outputId": "6edc21f6-0a51-4ad4-9917-813af5e04661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pydotplus.graphviz.Dot at 0x7f9640e9b550>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#terzo classificatore provato: Random Forest\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "features = data_labeled.drop(['Conto', 'Descrizione', 'Numero'], axis=1)\n",
        "targets = data_labeled.Conto\n",
        "descr = data_labeled.Descrizione\n",
        "num = data_labeled.Numero\n",
        "print(features.shape)\n",
        "\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "features.PrezzoUnitario = scaler.fit_transform(np.array(features.PrezzoUnitario).reshape(-1, 1))\n",
        "features.PrezzoTotale = scaler.fit_transform(np.array(features.PrezzoTotale).reshape(-1, 1))\n",
        "features.AliquotaIVA = scaler.fit_transform(np.array(features.AliquotaIVA).reshape(-1, 1))\n",
        "features.Year = scaler.fit_transform(np.array(features.Year).reshape(-1, 1))\n",
        "features.Month = scaler.fit_transform(np.array(features.Month).reshape(-1, 1))\n",
        "features.Day = scaler.fit_transform(np.array(features.Day).reshape(-1, 1))\n",
        "features.Similarity_Materie_Prime = scaler.fit_transform(np.array(features.Similarity_Materie_Prime).reshape(-1, 1))\n",
        "features.Similarity_Materie_Consumo = scaler.fit_transform(np.array(features.Similarity_Materie_Consumo).reshape(-1, 1))\n",
        "features.Similarity_Merci = scaler.fit_transform(np.array(features.Similarity_Merci).reshape(-1, 1))\n",
        "features.Similarity_Merci_Prodotti = scaler.fit_transform(np.array(features.Similarity_Merci_Prodotti).reshape(-1, 1))\n",
        "\n",
        "X_train = features.loc[540:,]\n",
        "X_test = features.loc[:539,]\n",
        "y_train = targets.loc[540:,]\n",
        "y_test = targets.loc[:539,]\n",
        "\"\"\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, shuffle=False)\n",
        "clf = RandomForestClassifier(n_estimators=50, max_depth=16, bootstrap = False)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "#print(clf.feature_importances_)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "#print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#Con la soglia scelta di default si scende di solito a 36 features\n",
        "\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "features_new = pd.DataFrame(model.transform(features))\n",
        "print(features_new.shape)\n",
        "print(features_new.head(5))\n",
        "\n",
        "X_train_new, X_test_new, y_train, y_test = train_test_split(features_new, targets, test_size=0.3, shuffle=False)\n",
        "clf2 = RandomForestClassifier(n_estimators=100, max_depth=15, bootstrap = False)\n",
        "y_pred2 = clf2.fit(X_train_new, y_train).predict(X_test_new)\n",
        "print(accuracy_score(y_test, y_pred2))\n",
        "\n",
        "print(f1_score(y_test, y_pred2, average=None))\n",
        "#print(f1_score(y_test, y_pred2, average='micro'))\n",
        "print(f1_score(y_test, y_pred2, average='macro'))\n",
        "print(f1_score(y_test, y_pred2, average='weighted'))\n",
        "\n",
        "#le performance, in quanto ad accuracy, sono paragonabili tra il modello con 204 features e quello ridotto e intorno \n",
        "#a 0.94/0.95. E' stata testata anche una pipeline che prevede prima una standardizzazione dei dati ma senza riportare\n",
        "#significative variazioni nella performance. Anche F-score assume più o meno gli stessi valori (nella versione weighted che tiene)\n",
        "#conto della dimensione delle classi). Invece la versione macro è potenzialmente anche più alta dell'accuracy perchè, come si \n",
        "#vede dalla confusion matrix, gli errori sono di solito sulle classe più grandi; a volte però si abbassa quando non viene appresa la classe\n",
        "#66/25/509, che ha poche istanze, e quindi il suo F score è 0.\n",
        "#Per sopperire alla momentanea scarsa precisione nel determinare l'accuracy a causa della mancata CV è stato anche usato come\n",
        "#test set la parte iniziale del dataset e viceversa per il training set rilevando le stesse performance che quindi si \n",
        "#possono considerare veritiere\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "dEelxyZ9TRbg",
        "outputId": "2eac353c-c07a-4a24-c4e6-b3207cfc1a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1816, 207)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-f1af87465af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \"\"\"\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0;34m\"test_size={0} should be either positive and smaller\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m             \u001b[0;34m\" than the number of samples {1} or a float in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m             \u001b[0;34m\"(0, 1) range\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2047\u001b[0m         )\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: test_size=0 should be either positive and smaller than the number of samples 1816 or a float in the (0, 1) range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=50, max_depth=16, bootstrap = False)\n",
        "clf.fit(features, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEgJ95qgDOet",
        "outputId": "98bd5dac-4e07-42d6-eda3-a7900521031e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, max_depth=16, n_estimators=50)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = '/content/finalized_model.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "GZkbihL7D9R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "6zt96eyuEMjL",
        "outputId": "6a5405bd-f177-48d8-dfa7-4906a0f6ece9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9944954128440368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature selection basata sul random forest, basata sulle features scelte inizialmente\n",
        "\n",
        "mask = clf.feature_importances_ > 0.03\n",
        "print(features.columns[mask])\n",
        "\n",
        "#Risultano importanti il prezzo unitario, il prezzo totale, l'IVA, il giorno (???), la modalità di pagamento e il codice cedente\n",
        "#Risultano poco importanti il prezzo totale, il mese e l'unità di misura\n",
        "#Risultano non importanti il codice cessionario, il tipo di documento, la condizione di pagamento e l'anno. In effetti queste features assumono sempre (o quasi)\n",
        "#lo stesso valore in questo dataset\n",
        "\n",
        "#Ho levato sin dall'inizio le features inutili (anche l'unità di misura) tenendo solo l'anno che può rivelarsi utile per un dataset \n",
        "#pluriennale. Le performance non ne risentono\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zfOtMFv9ibB",
        "outputId": "c9875b05-efd5-4a01-b771-5637735ae8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PrezzoUnitario', 'PrezzoTotale', 'AliquotaIVA',\n",
            "       'Similarity_Materie_Prime', 'Similarity_Materie_Consumo',\n",
            "       'Similarity_Merci', 'Similarity_Merci_Prodotti', 'Day',\n",
            "       'CodiceTipo_AswArtFor', 'ModalitaPagamento_MP01',\n",
            "       'ModalitaPagamento_MP19', 'CodiceCedente_10483110010',\n",
            "       'CodiceCedente_183410653', 'CodiceCedente_4352551214',\n",
            "       'CodiceCedente_777280157'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quarto classificatore provato: AdaBoost\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "features = data_labeled.drop(['Conto'], axis=1)\n",
        "targets = data_labeled.Conto\n",
        "#print(features.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, shuffle=False)\n",
        "clf = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=8), n_estimators=100)\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#accuracy intorno a 0.94/0.95, come RF, però non funziona la feature selection. Se uso le 36 features selezionate da RF l'accuracy cala di circa 1%,\n",
        "#probabilmente perchè non sono le features adatte ad AdaBoost.\n",
        "#L'accuracy sale fino a 0.96/0.97 se la dimensione del training viene aumentata (90% dei dati) a scapito di quella del test set, cosa che \n",
        "#non accade nel RF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLjjVHQTJzTG",
        "outputId": "fe3206f3-ede7-4607-97f7-ce58a124afd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9424860853432282\n",
            "[0.9539749  0.93922652 0.88888889 0.93436293 1.         1.\n",
            " 0.72727273 1.         0.97959184 1.         1.        ]\n",
            "0.9424860853432282\n",
            "0.9475743456357955\n",
            "0.9422508830920644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quinto classificatore provato: SVC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "features = data_labeled.drop(['Conto'], axis=1)\n",
        "\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "features.PrezzoUnitario = scaler.fit_transform(np.array(features.PrezzoUnitario).reshape(-1, 1))\n",
        "features.PrezzoTotale = scaler.fit_transform(np.array(features.PrezzoTotale).reshape(-1, 1))\n",
        "features.AliquotaIVA = scaler.fit_transform(np.array(features.AliquotaIVA).reshape(-1, 1))\n",
        "features.Year = scaler.fit_transform(np.array(features.Year).reshape(-1, 1))\n",
        "features.Month = scaler.fit_transform(np.array(features.Month).reshape(-1, 1))\n",
        "features.Day = scaler.fit_transform(np.array(features.Day).reshape(-1, 1))\n",
        "\"\"\"\n",
        "\n",
        "print(features.columns)\n",
        "targets = data_labeled.Conto\n",
        "#print(features.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.3, shuffle=False)\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='scale'))\n",
        "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(y_test, y_pred, average=None))\n",
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "print(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "#performance intorno a 0.87, anche al variare di alcuni parametri come il coefficiente di regolarizzazione C e gamma.\n",
        "#Non cambia praticamente niente se si normalizzano tutte le feature o solo quelle numeriche.\n",
        "#Nei 2 modelli migliori (AdaBoost e RF) l'accuracy e F score sono allineati, nei modelli peggiori come appunto SVC, F score\n",
        "#in modalità macro risente del fatto che alcune classi non vengono apprese e perciò hanno F score individuale uguale a 0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHBpvpUi4yTU",
        "outputId": "aa0b41e8-1ad7-4f12-fbbe-8d9a8f8b90dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PrezzoUnitario', 'PrezzoTotale', 'AliquotaIVA',\n",
            "       'Similarity_Materie_Prime', 'Similarity_Materie_Consumo',\n",
            "       'Similarity_Merci', 'Similarity_Merci_Prodotti', 'Year', 'Month', 'Day',\n",
            "       ...\n",
            "       'NumeroDDT_PKL.21.1321', 'NumeroDDT_PKL.21.1457',\n",
            "       'NumeroDDT_PKL.21.161', 'NumeroDDT_PKL.21.195', 'NumeroDDT_PKL.21.471',\n",
            "       'NumeroDDT_PKL.21.520', 'NumeroDDT_PKL.21.55', 'NumeroDDT_PKL.21.597',\n",
            "       'NumeroDDT_PKL.21.914', 'NumeroDDT_PKL.21.97'],\n",
            "      dtype='object', length=204)\n",
            "0.8534322820037106\n",
            "[0.87826087 0.88297872 0.9044586  0.81506849 0.         0.\n",
            " 0.         1.         0.82758621 0.99130435 1.        ]\n",
            "0.8534322820037106\n",
            "0.6636052035971737\n",
            "0.8332993756936149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo di quali classi sono presenti nel train set, nel test set e quali vengono effettivamente predette\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(np.unique(y_train))\n",
        "print(np.unique(y_test))\n",
        "print(np.unique(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flBtA9Qqdsqu",
        "outputId": "0ab7d254-1054-41a5-ffdc-e15cfae88f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['66/05/006' '66/20/005' '66/25/005' '66/25/006' '66/25/506' '66/25/507'\n",
            " '66/25/509' '66/30/015' '66/30/017' '66/30/055' '68/05/025' '68/05/490'\n",
            " '70/05/101']\n",
            "['66/05/006' '66/20/005' '66/25/005' '66/25/006' '66/25/506' '66/25/509'\n",
            " '66/30/015' '66/30/017' '66/30/055' '68/05/025' '68/05/490']\n",
            "['66/05/006' '66/20/005' '66/25/005' '66/25/006' '66/25/506' '66/25/509'\n",
            " '66/30/015' '66/30/017' '66/30/055' '68/05/025' '68/05/490']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo della numerosità delle varie classi nei set\n",
        "res = {}\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "for i,j in zip(unique, counts):\n",
        "  res[i] = {'train' : j}\n",
        "\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "for i,j in zip(unique, counts):\n",
        "  res[i]['test'] = j\n",
        "\n",
        "unique, counts = np.unique(y_pred, return_counts=True)\n",
        "for i,j in zip(unique, counts):\n",
        "  res[i]['pred'] = j\n",
        "\n",
        "for k,v in res.items():\n",
        "  print(k,v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ran3tMR4lKPg",
        "outputId": "59704158-3ec3-4b07-be7e-ce14ed905193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66/05/006 {'train': 256, 'test': 121, 'pred': 121}\n",
            "66/20/005 {'train': 166, 'test': 89, 'pred': 90}\n",
            "66/25/005 {'train': 200, 'test': 86, 'pred': 74}\n",
            "66/25/006 {'train': 285, 'test': 129, 'pred': 142}\n",
            "66/25/506 {'train': 14, 'test': 20, 'pred': 20}\n",
            "66/25/507 {'train': 13}\n",
            "66/25/509 {'train': 6, 'test': 2, 'pred': 2}\n",
            "66/30/015 {'train': 17, 'test': 6, 'pred': 4}\n",
            "66/30/017 {'train': 5, 'test': 3, 'pred': 3}\n",
            "66/30/055 {'train': 39, 'test': 24, 'pred': 24}\n",
            "68/05/025 {'train': 236, 'test': 57, 'pred': 57}\n",
            "68/05/490 {'train': 6, 'test': 2, 'pred': 2}\n",
            "70/05/101 {'train': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix per analisi degli errori piu comuni\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n",
        "\n",
        "confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
        "\n",
        "#con l'aggiunta delle informazioni estratte dalla descrizione le performance migliorano ma gli errori restano relativi alle stesse\n",
        "#categorie di prima, in misura minore. Fortunatamente queste features aggiuntive non creano ocnfusione nelle altre classi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iCowoHVoGqA",
        "outputId": "017edf29-8ca1-43fb-9466-976e77847fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'66/05/006': 121, '66/20/005': 89, '66/25/005': 86, '66/25/006': 129, '66/25/506': 20, '66/25/509': 2, '66/30/015': 6, '66/30/017': 3, '66/30/055': 24, '68/05/025': 57, '68/05/490': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[115,   4,   0,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  3,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,  71,  15,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  2,   0,   3, 124,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,  20,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0],\n",
              "       [  0,   2,   0,   0,   0,   0,   4,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  24,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  57,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analisi dell'effettiva informazione portata dalle features di similarity\n",
        "\n",
        "print(data_labeled.groupby('Conto').mean()[['Similarity_Materie_Prime', 'Similarity_Materie_Consumo']])\n",
        "print(data_labeled.groupby('Conto').mean()[['Similarity_Merci', 'Similarity_Merci_Prodotti']])\n",
        "\n",
        "#per 3 classi su 4 effettivamente le features di similarità si comportano come previsto. Andrebbe migliorata la scelta delle\n",
        "#parole tipiche delle descrizioni del gruppo 66/25/005, che in effetti è il gruppo su cui vengono ancora commessi la maggior parte\n",
        "#degli errori, scambiandola con la classe 66/25/006"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHuGpCpnS3rb",
        "outputId": "6040981c-59ce-4d7d-bd6b-28299a86a346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Similarity_Materie_Prime  Similarity_Materie_Consumo\n",
            "Conto                                                          \n",
            "66/05/006                  0.418216                    0.252536\n",
            "66/20/005                  0.266449                    0.326461\n",
            "66/25/005                  0.256683                    0.221359\n",
            "66/25/006                  0.298135                    0.245962\n",
            "66/25/506                  0.255085                    0.217104\n",
            "66/25/507                  0.388502                    0.265801\n",
            "66/25/509                  0.437905                    0.340030\n",
            "66/30/015                  0.237376                    0.289640\n",
            "66/30/017                  0.227693                    0.252930\n",
            "66/30/055                  0.200202                    0.245510\n",
            "68/05/025                  0.193863                    0.193651\n",
            "68/05/490                  0.209511                    0.264706\n",
            "70/05/101                  0.201765                    0.201089\n",
            "           Similarity_Merci  Similarity_Merci_Prodotti\n",
            "Conto                                                 \n",
            "66/05/006          0.311902                   0.287691\n",
            "66/20/005          0.266703                   0.281795\n",
            "66/25/005          0.285107                   0.247275\n",
            "66/25/006          0.282929                   0.361863\n",
            "66/25/506          0.183699                   0.240781\n",
            "66/25/507          0.275671                   0.290239\n",
            "66/25/509          0.280861                   0.291721\n",
            "66/30/015          0.271881                   0.230168\n",
            "66/30/017          0.240057                   0.252635\n",
            "66/30/055          0.111518                   0.176786\n",
            "68/05/025          0.134417                   0.182084\n",
            "68/05/490          0.193307                   0.201997\n",
            "70/05/101          0.182415                   0.165955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#per verificare se le performance migliorano in qualunque delle configurazioni successive, voglio avere gli stess1 identici\n",
        "#test set e training set. \n",
        "\n",
        "data_test = data_labeled.loc[1255:1793,:]\n",
        "print(data_test)\n",
        "\n",
        "data_train = data_labeled.loc[:1254,:]\n",
        "print(data_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NizDvqe-aHE-",
        "outputId": "47b8b442-ba8a-487a-8dd0-e9b135ab2ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Numero  PrezzoUnitario  ...  NumeroDDT_PKL.21.97      Conto\n",
            "1255  16119          0.0000  ...                    0  66/25/006\n",
            "1256  16119          1.3500  ...                    0  66/25/006\n",
            "1257  16119          0.0000  ...                    0  66/25/006\n",
            "1258  16119          4.3500  ...                    0  66/25/006\n",
            "1259  16119          0.0000  ...                    0  66/25/006\n",
            "...     ...             ...  ...                  ...        ...\n",
            "1789    863          0.9836  ...                    0  66/20/005\n",
            "1790    863          1.1475  ...                    0  66/20/005\n",
            "1791    863          0.5328  ...                    0  66/20/005\n",
            "1792   1682          0.0000  ...                    0  66/05/006\n",
            "1793   1682          0.0880  ...                    0  66/05/006\n",
            "\n",
            "[539 rows x 207 columns]\n",
            "              Numero  PrezzoUnitario  ...  NumeroDDT_PKL.21.97      Conto\n",
            "0     CI202074250324          17.980  ...                    0  66/25/005\n",
            "1     CI202074250324           0.053  ...                    0  66/25/005\n",
            "2              14587          19.000  ...                    0  66/25/006\n",
            "3              14587           0.000  ...                    0  66/25/006\n",
            "4              14587           1.350  ...                    0  66/25/006\n",
            "...              ...             ...  ...                  ...        ...\n",
            "1250          12/976           1.600  ...                    0  66/25/006\n",
            "1251             783           0.000  ...                    0  66/25/506\n",
            "1252             783           2.000  ...                    0  66/25/506\n",
            "1253             783           0.000  ...                    0  66/25/506\n",
            "1254           16119          19.000  ...                    0  66/25/006\n",
            "\n",
            "[1255 rows x 207 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ora creo il dataset per il semi supervised training con le 1255 unità non usate per il test e tutte quelle con 'Conto' NaN.\n",
        "#Inoltre viene performato l'encoding delle labels per non avere stringhe e -1 ma solo interi\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(data_labeled['Conto'])\n",
        "data_labeled['Conto'] = le.transform(data_labeled['Conto'])\n",
        "data_semi = pd.concat(objs=[data_train, data_unlabeled])\n",
        "data_semi.reset_index(inplace=True)\n",
        "data_semi = data_semi.drop('index', axis=1)\n",
        "data_semi = data_semi.fillna(-1)\n",
        "print(data_semi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIE3eju-7q3v",
        "outputId": "ecf2577e-2a0e-4fb7-894f-401c78f31157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      PrezzoUnitario  PrezzoTotale  ...  NumeroDDT_PKL.21.97  Conto\n",
            "0             17.980        308.16  ...                    0      2\n",
            "1              0.053          1.06  ...                    0      2\n",
            "2             19.000        369.36  ...                    0      3\n",
            "3              0.000          0.00  ...                    0      3\n",
            "4              1.350         27.00  ...                    0      3\n",
            "...              ...           ...  ...                  ...    ...\n",
            "5311           0.000          0.00  ...                    0     -1\n",
            "5312           0.000          0.00  ...                    0     -1\n",
            "5313           0.000          0.00  ...                    0     -1\n",
            "5314           0.000          0.00  ...                    0     -1\n",
            "5315          10.000         10.00  ...                    0     -1\n",
            "\n",
            "[5316 rows x 205 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ora il dataset data_semi è pronto per il semi supervised learning dato che ha dei -1 al posto dei target mancanti\n",
        "\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#clf = make_pipeline(StandardScaler(), SVC(gamma='scale', probability=True))\n",
        "#clf = tree.DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)\n",
        "clf = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=8), n_estimators=100)\n",
        "calibrated_clf = CalibratedClassifierCV(base_estimator=clf)\n",
        "\n",
        "X = data_semi.drop('Conto', axis=1)\n",
        "y = data_semi.Conto\n",
        "calibrated_clf.fit(X, y)\n",
        "\n",
        "self_training_model = SelfTrainingClassifier(calibrated_clf, threshold=0.95, max_iter=2)\n",
        "self_training_model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwzgHwT7mkK2",
        "outputId": "2f9c5312-d27e-4704-d3ab-5cb648ede903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelfTrainingClassifier(base_estimator=CalibratedClassifierCV(base_estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=8),\n",
              "                                                                                               n_estimators=100)),\n",
              "                       max_iter=2, threshold=0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo di quali samples sono stati labeled e a che iterazione\n",
        "\n",
        "for i in range(len(self_training_model.labeled_iter_)):\n",
        "  print(self_training_model.labeled_iter_[i])\n",
        "  print(self_training_model.transduction_[i])\n"
      ],
      "metadata": {
        "id": "SgLxUPBMCmnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creazione del nuovo training set con l'aggiunta dei nuovi dati pseudo supervisionati\n",
        "\n",
        "mask = self_training_model.labeled_iter_ != -1\n",
        "data_train = data_semi.loc[mask,]\n",
        "data_train.Conto = self_training_model.transduction_[mask]\n",
        "print(data_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q-GLd2uFVPx",
        "outputId": "de8121f7-2e7f-421d-8b51-e2f4eb9fcf92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      PrezzoUnitario  PrezzoTotale  ...  NumeroDDT_PKL.21.97  Conto\n",
            "0             17.980        308.16  ...                    0      2\n",
            "1              0.053          1.06  ...                    0      2\n",
            "2             19.000        369.36  ...                    0      3\n",
            "3              0.000          0.00  ...                    0      3\n",
            "4              1.350         27.00  ...                    0      3\n",
            "...              ...           ...  ...                  ...    ...\n",
            "5162           0.300          0.30  ...                    0      9\n",
            "5205           0.300          0.30  ...                    0      9\n",
            "5239           0.300          0.30  ...                    0      9\n",
            "5240           0.000          0.00  ...                    0      0\n",
            "5310           0.300          0.30  ...                    0      9\n",
            "\n",
            "[1860 rows x 205 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo delle performance predittive grazie all'aumento dei samples supervisionati, usando lo stesso test set\n",
        "#del caso senza semi supervised learning\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(self_training_model.predict(data_test.drop('Conto', axis=1)), le.transform(data_test.Conto)))\n",
        "\n",
        "#purtroppo le performance non migliorano come sperato a prescindere da quanto venga ampliato il training set grazie al semi supervised learning,\n",
        "#anche se vengono recuperate solo labels ad alta confidenza"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBSHWzE0rsgu",
        "outputId": "0f02860a-6a5d-402b-dac4-20e24040b852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9461966604823747\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PrimeOffice.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

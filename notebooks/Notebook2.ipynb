{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PrimeOfficeModifiche.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txxhJO0yvapu",
        "outputId": "d2af7a59-9f89-47b8-e87d-f4e684e1e984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#NOTEBOOK 2: implementazione della CV per una stima più accurata delle performance del classificatore e di una versione\n",
        "#di pseudo-labeling in approccio semi-supervised che accetti solo labels certificate\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lettura del file excel prodotto dal Notebook 1 in pandas\n",
        "\n",
        "import pandas as pd\n",
        "!pip install --upgrade openpyxl\n",
        "\n",
        "data = pd.read_excel('/content/drive/MyDrive/df_preprocessed.xlsx')\n",
        "data = data.drop('Unnamed: 0', axis=1)\n",
        "#print(data.head)\n",
        "print(data.columns)\n",
        "print(data.shape)\n",
        "\n",
        "#totale righe: 5877"
      ],
      "metadata": {
        "id": "vD9hOtBvzYA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef794ba0-034d-4eb8-80fb-b636e7a8b10c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.9)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Index(['Descrizione', 'Numero', 'PrezzoUnitario', 'PrezzoTotale',\n",
            "       'AliquotaIVA', 'Conto', 'Year', 'Month', 'Day', 'CodiceTipo_',\n",
            "       ...\n",
            "       'yes', 'yoga', 'yogurt', 'yonkers', 'zacapa', 'zenzero', 'zero',\n",
            "       'zuccheriera', 'zucchero', 'zucher'],\n",
            "      dtype='object', length=1564)\n",
            "(5877, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminazione delle righe ausiliarie\n",
        "\n",
        "mask = (data.Descrizione != 'Riga ausiliaria contenente informazioni tecniche e aggiuntive del documento')\n",
        "data = data[mask]\n",
        "data.reset_index(inplace=True)\n",
        "data = data.drop('index', axis=1)\n",
        "\n",
        "#print(data)\n",
        "\n",
        "#rimangono 5692 righe"
      ],
      "metadata": {
        "id": "TDoxksY81eO7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#in vista del semi supervised learning, separazione dei dati supervisionati e non supervisionati\n",
        "\n",
        "from sklearn.semi_supervised import SelfTrainingClassifier\n",
        "\n",
        "data_labeled = data[data['Conto'].notna()]\n",
        "data_unlabeled = data[data['Conto'].isnull()]\n",
        "\n",
        "data_labeled.reset_index(inplace=True)\n",
        "data_labeled = data_labeled.drop('index', axis=1)\n",
        "data_unlabeled.reset_index(inplace=True)\n",
        "data_unlabeled = data_unlabeled.drop('index', axis=1)\n",
        "\n",
        "print(data_labeled.shape)\n",
        "print(data_unlabeled.shape)"
      ],
      "metadata": {
        "id": "qB6Lr0hdwxhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55b4d9cd-315f-4ba6-a6e5-515e724980e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1805, 1564)\n",
            "(3887, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC 1: introduzione anche della validazione fatta per CV. Con questa tecnica è possibile operare una grid\n",
        "#search nello spazio degli iperparametri in fase di validazione senza ridurre il training set ma anche avere una stima\n",
        "#più accurata della metrica di valutazione. \n",
        "#Inoltre, er avere un risultato paragonabile al caso base nel Notebook 1 quando testerò il modello validato, uso lo stesso\n",
        "#training e lo stesso test set\n",
        "\n",
        "mask = (data_labeled['Conto'] != '18/40/501')&(data_labeled['Conto'] != '66/25/505')&(data_labeled['Conto'] != '66/25/508')&(data_labeled['Conto'] != '66/30/060')&(data_labeled['Conto'] != '68/05/005')&(data_labeled['Conto'] != '68/05/133')&(data_labeled['Conto'] != '68/05/290')&(data_labeled['Conto'] != '68/05/320')&(data_labeled['Conto'] != '68/05/385')&(data_labeled['Conto'] != '68/05/407')&(data_labeled['Conto'] != '88/20/035')\n",
        "data_labeled2 = data_labeled[mask]\n",
        "data_labeled2.reset_index(inplace=True)\n",
        "data_labeled2 = data_labeled2.drop('index', axis=1)\n",
        "\n",
        "data_test = data_labeled2.loc[1249:,:]\n",
        "#print(data_test)\n",
        "\n",
        "data_train = data_labeled2.loc[:1248,:]\n",
        "#print(data_train)\n",
        "\n",
        "#quando elimino i conti rari però non sovrascrivo data_labeled che serve integro nella successiva applicazione del semi\n",
        "#supervised learning"
      ],
      "metadata": {
        "id": "HwM4zXkavpD3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Osservato che accuracy e F1 score danno indicazioni simili (nel Notebook 1) si procede con l'accuracy che è più interpretabile; mentre per\n",
        "#quanto riguarda i modelli si procede con RF e AdaBoost.\n",
        "#La tecnica di CV scelta è StratifiedGroupKFold a causa dello sbilanciamento delle classi e della presenza di gruppi fra\n",
        "#i samples (i.e. righe fattura), cioè le fatture stesse identificate dai numeri di fattura.\n",
        "\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "X = data_train.drop(['Conto', 'Numero', 'Descrizione'], axis = 1)\n",
        "y = data_train.Conto\n",
        "groups = data_train.Numero\n",
        "\n",
        "cv = StratifiedGroupKFold(n_splits=5)"
      ],
      "metadata": {
        "id": "aq_j4XJMCPhm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stima delle metriche tramite 5-fold CV\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "\n",
        "#clf = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=8), n_estimators=100)\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=30, bootstrap = False)\n",
        "scores1 = cross_val_score(clf, X, y, cv=cv, scoring='accuracy', groups=groups)\n",
        "scores2 = cross_val_score(clf, X, y, cv=cv, scoring='f1_weighted', groups=groups)\n",
        "scores3 = cross_val_score(clf, X, y, cv=cv, scoring='f1_macro', groups=groups)\n",
        "print(scores1)\n",
        "print(scores2)\n",
        "print(scores3)\n",
        "\n",
        "#anche le stime per CV confermano sostanzialmente quelle fatte per hold-out: accuracy e F1 weighted a 0.94/0.95, se si ignora\n",
        "#il primo fold. F1 macro è più bassa a causa di alcune piccole classi non predette correttamente nella divisione in folds."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrbRbfMmvpGr",
        "outputId": "06239158-fb89-4e69-b266-85c27ca3df88"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.57594937 0.97407407 0.9123506  0.93658537 0.93236715]\n",
            "[0.52555567 0.96244816 0.9175626  0.91858397 0.92314966]\n",
            "[0.72033757 0.80311284 0.68525957 0.84243789 0.87706362]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analisi del perchè (a prescindere dal numero di folds scelto) il primo score è bassissimo.\n",
        "\n",
        "unique, counts = np.unique(groups, return_counts=True)\n",
        "print(unique)\n",
        "print(counts)\n",
        "\n",
        "#c'è un gruppo (il numero fattura è 1200261973) numerosissimo con 125 istanze e tutte hanno label 66/25/005,\n",
        "#perciò quando a questo gruppo tocca fare da test l'algoritmo non impara a riconoscere tale classe e sbaglia la predizione\n",
        "#su gran parte degli elementi abbassando drasticamente la metrica.\n",
        "\n",
        "for train_idxs, test_idxs in cv.split(X, y, groups):\n",
        "  print(np.unique(groups[train_idxs]))\n",
        "  print(np.unique(groups[test_idxs]))\n",
        "\n",
        "#come prevedibile, il gruppo con numero di fattura 1200261973 è nel test al primo split, per questo le metriche associate \n",
        "#sono così basse. Tali gruppi così sbilanciati rendono impossibile un'adeguata stratificazione, ma comunque StratifiedGroupKFold\n",
        "#lavora meglio di GroupKFold"
      ],
      "metadata": {
        "id": "K0p9j-XdvpKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ricerca dei migliori iper-parametri (numero di alberi e profondità) per RF grazie alla CV\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'n_estimators': (25, 50, 100, 200, 500), 'max_depth': (5, 8, 10, 12, 15, 20, 25, 30, 50, 100, 200)}\n",
        "rf = RandomForestClassifier(bootstrap = False)\n",
        "clf = GridSearchCV(rf, parameters, cv=cv, scoring='accuracy')\n",
        "clf.fit(X, y, groups=groups)\n",
        "\n",
        "print(clf.best_params_)\n",
        "\n",
        "#risulta ottimale usare alberi abbastanza profondi (learners overfittati tanto la varianza viene abbassata dall'averaging siccome RF è un\n",
        "#metodo di bagging), ma comunque da profondità 25 circa in poi non fa grande differenza, come evidente dalla cella sotto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4clkKWVvpNn",
        "outputId": "c90f06c0-1c03-4a73-f9a6-7e124572ad6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 30, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#performance su tutte le possibili coppie di iper parametri in termini di accuracy. I valori non sono intorno a 0.94, come\n",
        "#nelle stime con hold-out, per via del primo fold di CV su cui performa male\n",
        "\n",
        "means = clf.cv_results_[\"mean_test_score\"]\n",
        "stds = clf.cv_results_[\"std_test_score\"]\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n"
      ],
      "metadata": {
        "id": "9EDb6XMWvpRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test sul solito test set finora tenuto in disparte\n",
        "\n",
        "y_pred = clf.predict(data_test.drop(['Conto', 'Numero', 'Descrizione'], axis = 1))\n",
        "print(accuracy_score(data_test.Conto, y_pred))\n",
        "\n",
        "#dato che la grid search non ha evidenziato coppie di iper-paramentri molto migliori di quelli usati a occhio precedentemente\n",
        "#non c'è da stupirsi che l'accuracy sul test sia intorno a 0.94/0.95"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1XWb-DIvpVu",
        "outputId": "30a019a6-5e24-4ddd-edda-420d7553c8d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9531835205992509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#come boosting method Gradient Boosting invece che AdaBoost perchè quest'ultimo prende il modello da boostare\n",
        "#come iper-paramentro e non la profondità dell'albero. Per il resto la procedura è uguale a quella sopra per RF eccetto\n",
        "#che si usano alberi meno profondi perchè per i metodi di boosting sono richiesti weak learners e la griglia degli\n",
        "#iper-parametri è tridimensionale\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "parameters = {'n_estimators': (50, 100, 200), 'max_depth': (3, 4, 5), 'learning_rate': (0.1, 1.0)}\n",
        "gbc = GradientBoostingClassifier()\n",
        "clf = GridSearchCV(gbc, parameters, cv=cv, scoring='accuracy')\n",
        "clf.fit(X, y, groups=groups)\n",
        "\n",
        "print(clf.best_params_)\n",
        "\n",
        "#il fitting richiede molto più tempo di RF e come prevedibile è ottimizzato da learners poco profondi"
      ],
      "metadata": {
        "id": "URBTmeN0vpXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(data_test.drop(['Conto', 'Numero', 'Descrizione'], axis = 1))\n",
        "print(accuracy_score(data_test.Conto, y_pred))\n",
        "\n",
        "#anche per questo ensemble method si ottengono performance paragonabili a RF e AdaBoost, forse leggermente peggiore\n",
        "#(potrebbe essere dovuto al fatto che la grid search è stata fatta piu ristretta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veCljUbfwHHD",
        "outputId": "341e4b25-ae4a-4a1b-866d-7f98e4329cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9344569288389513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC 2: implementazione del semi supervised learning con validazione delle pseudo-label grazie agli\n",
        "#ammontari associati a ciascun conto in prima nota. Per prima cosa viene caricato il modello di classificazione\n",
        "#RF trainato su tutti i dati nel notebook 1(senza dividere tra training e test set e senza escludere i samples con conti rari, così\n",
        "#da massimizzare la probabilità di assegnare correttamente una pseudo-label)\n",
        "\n",
        "import pickle\n",
        "\n",
        "clf = pickle.load(open('/content/drive/MyDrive/finalized_model.sav', 'rb'))\n",
        "print(clf)\n",
        "\n",
        "#in seguito alle considerazioni fatte con la grid search per CV è un RF con 100 alberi di profondità massima 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lULaFIB2EjUD",
        "outputId": "72a4791b-1212-4266-dd00-728fdd94e174"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(bootstrap=False, max_depth=30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selezione, tra i samples senza conto a cui si punta ad associare una pseudo-label, dei soli matchabili ovvero\n",
        "#quelli aventi, innanzitutto, un corrispondente in prima nota\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "prima_nota = pd.read_excel('/content/df_row.xlsx')\n",
        "prima_nota = prima_nota.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "numeri_fattura_registrati = np.unique(prima_nota['ND ori.'])\n",
        "mask = []\n",
        "for elem in data_unlabeled.Numero:\n",
        "  mask.append(elem in numeri_fattura_registrati)\n",
        "\n",
        "data_unlabeled2 = data_unlabeled[mask]\n",
        "data_unlabeled2.reset_index(inplace=True)\n",
        "data_unlabeled2 = data_unlabeled2.drop('index', axis=1)\n",
        "\n",
        "print(data_unlabeled2.shape)\n",
        "\n",
        "#su 3887 dati unsupervised, solo 1297 di essi hanno il corrispondente in prima nota"
      ],
      "metadata": {
        "id": "ccmteK8BF8Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db335ea5-b41c-49ce-a5d4-24de19549475"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1297, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bisogna però osservare che, in alcuni casi, pur essendoci la corrispondente registrazione in prima nota, gli ammontari non\n",
        "#coincidono, probabilmente a causa di qualche errore. Ricerca di questi casi (usando una soglia di 0.02 con l'idea che un errore\n",
        "#maggiore di questo non è attribuibile ad approssimazioni)\n",
        "\n",
        "all_fatture = list(np.unique(data_unlabeled2.Numero))\n",
        "\n",
        "non_corresponding = []\n",
        "\n",
        "for numero_fattura in all_fatture:\n",
        "  ammontare_righe_fattura = np.sum(data_unlabeled2.PrezzoTotale[(data_unlabeled2['Numero'] == numero_fattura)])\n",
        "  ammontare_prima_nota = np.sum((prima_nota.Importo[(prima_nota['ND ori.'] == numero_fattura)].values)[2:])\n",
        "  if np.abs(ammontare_righe_fattura - ammontare_prima_nota) > 0.02:\n",
        "    non_corresponding.append(numero_fattura)\n",
        "\n",
        "print(non_corresponding)\n",
        "print(len(non_corresponding))\n",
        "\n",
        "#I motivi di incongruenza delle 31 fatture non_corresponding possono essere vari. Alcuni esempi a seguire.\n",
        "#numeri strani: 423, in prima nota sono registrate tutte nel conto \"vino\", ma palesemente dalla descrizione non si tratta\n",
        "#di vino, inoltre l'ammontare è 89.38 ma in prima nota è segnato 120. 1101, l'ammontare è 210 ma in prima nota è segnato\n",
        "#62.64. 112, anche qua non coincidono gli ammontari, inoltre, l'algoritmo assegna giustamente il conto \"vino\" (si vede dalla descrizione)\n",
        "#mentre in prima nota queste spese sono registrate come \"materie di consumo\", infine, essendoci un solo conto sarebbe risolvibile\n",
        "#il knapsack ma dato che gli ammontari non tornano non trova nessuna soluzione ammissibile. 119, stesso problema. 2253/C, \n",
        "#non tutte le righe fattura sono registrate in prima nota (solo 2 su 4), perciò ovviamente gli ammontari non tornano.\n",
        "#12/1040, sebbene abbia solo 5 righe e 2 conti non viene risolto dal knapsack perchè gli ammontari in fattura e prima nota differiscono\n",
        "#di 0.01 mentre nella funzione di match si è usata come soglia max 0.001. Simile per 2069036018. Queste comunque non\n",
        "#risultano nelle non_corresponding a causa della soglia 0.02 usata sopra, dato che sono recuperabili con A* con la soglia opportuna."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDEobzapVPaY",
        "outputId": "6a96cf79-5bf9-4f91-b487-6d882c722e44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1042', '1101', '112', '119', '131', '1402', '150', '166', '17', '202022547923', '202022602551', '202022656839', '2020FTA.20.003470', '2253/C', '25', '2635', '27', '3', '31', '34', '4', '41', '423', '57', '58', '59440', '635', '7', '9', '90', 'FPR 127/20']\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for elem in list(data_unlabeled2.Numero):\n",
        "  if elem in non_corresponding:\n",
        "    count = count + 1\n",
        "\n",
        "print(count)\n",
        "\n",
        "#altre 141 righe non sono matchabili a priori perchè, pur essendoci la registrazione in prima nota, gli ammontari non tornano"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY7GnCmkWttx",
        "outputId": "b7f643a0-270a-442c-9dc1-3d0fcc57e408"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rimuovo le corrispondenti fatture da data_unlabeled2, per lo stesso motivo per cui avevo rimosso quelle senza corrispondente \n",
        "#in prima nota\n",
        "\n",
        "mask = []\n",
        "for elem in data_unlabeled2.Numero:\n",
        "  mask.append(elem not in non_corresponding)\n",
        "\n",
        "data_unlabeled3 = data_unlabeled2[mask]\n",
        "data_unlabeled3.reset_index(inplace=True)\n",
        "data_unlabeled3 = data_unlabeled3.drop('index', axis=1)\n",
        "\n",
        "print(data_unlabeled3.shape)\n",
        "\n",
        "#dunque sono 1156 le righe fattura potenzialmente recuperabili con le pseudo-labels perchè solo per queste c'è un'affidabile registrazione\n",
        "#in prima nota per validare le pseudo-label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWAT5pJQavAw",
        "outputId": "a5503116-1ae6-4ba6-9897-ba74499c8ecc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1156, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inoltre, solo se i conti della registrazione in prima nota sono conti noti nel training il nostro metodo di pseudo-labeling\n",
        "#può funzionare. Per trovare i conti noti si osserva data_labeled e non data_labeled2 in cui i conti poco comuni sono stati eliminati\n",
        "\n",
        "conti_noti = np.unique(data_labeled.Conto)\n",
        "mask2 = []\n",
        "for numero_fattura in data_unlabeled3.Numero:\n",
        "  boolean = True\n",
        "  conti_prima_nota = prima_nota.Conto[(prima_nota['ND ori.'] == numero_fattura)]\n",
        "  for conto in conti_prima_nota[2:]:\n",
        "    if not (conto in conti_noti):\n",
        "      boolean = False\n",
        "  mask2.append(boolean)\n",
        "\n",
        "print(mask2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9F5PLe8L5dc",
        "outputId": "82463bfa-4853-4ca7-9b18-e946ad8daaae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#analisi dei samples rimasti\n",
        "\n",
        "data_unlabeled3 = data_unlabeled3[mask2]\n",
        "data_unlabeled3.reset_index(inplace=True)\n",
        "data_unlabeled3 = data_unlabeled3.drop('index', axis=1)\n",
        "\n",
        "print(data_unlabeled3.shape)\n",
        "\n",
        "#delle 1156 rimangono 1049 samples potenzialmente pseudo-etichetabili; gli altri hanno delle registrazioni in prima nota\n",
        "#mai viste nel training set dal classificatore"
      ],
      "metadata": {
        "id": "l4-uAfGGSOpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93309dd9-c5ab-4398-ef48-b80aaa6020b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1049, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#classificazione delle 1049 righe rimaste tramite il classificatore RF trainato su tutti i dati noti\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "features = data_unlabeled3.drop(['Conto', 'Descrizione', 'Numero'], axis=1)\n",
        "descr = data_unlabeled3.Descrizione\n",
        "num = data_unlabeled3.Numero\n",
        "\n",
        "y_pred = clf.predict(features)\n",
        "print(len(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu75tvyoZYua",
        "outputId": "aca60646-8bf2-4f1c-fa1e-57377d92cc0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creazione del file con le pseudo-labels da trattare con A*\n",
        "\n",
        "pseudo_labels = pd.concat(objs=(data_unlabeled3.Numero, pd.Series(y_pred, name='Conto'), data_unlabeled3.PrezzoTotale), axis=1)\n",
        "print(pseudo_labels.shape)\n",
        "print(pseudo_labels.columns)\n",
        "\n",
        "pseudo_labels.to_excel('/content/pseudo_labels2.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoPqXUQ2o2Xe",
        "outputId": "fa8890a7-b9f2-4f6c-dc6e-f4c61ae4cdea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1049, 3)\n",
            "Index(['Numero', 'Conto', 'PrezzoTotale'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IN REALTA' DA QUANDO HO L'ALGORITMO A* SU PYCHARM LE PROSSIME 3 CELLE SONO SUPERFLUE PERCHE' QUESTA VALIDAZIONE NON E' \n",
        "#ALTRO CHE IL RAGGIUNGIMENTO DEL GOL CON A* IN 0 PASSI\n",
        "\n",
        "#per la validazione bisogna fare un controllo incrociato con i valori registrati in prima nota per ogni fattura e per ogni\n",
        "#conto: se tutti i check corrispondono allora si possono validare tutte le predizioni effettutate sulle righe di tale fattura.\n",
        "#Per procedere si cicla su entrambi gli indici dell'oggetto raggruppato; ad ogni iterazione idx contiene i 2 indici gerarchici\n",
        "#e data il valore numerico associato a tale registrazione.\n",
        "\n",
        "df = pd.concat(objs=[data_unlabeled3.Numero, data_unlabeled3.Descrizione, pd.Series(y_pred).rename('Conto'), data_unlabeled3.PrezzoTotale], axis=1)\n",
        "grouped = df.groupby(['Numero', 'Conto']).sum()\n",
        "\n",
        "print(grouped)\n",
        "\n",
        "validated = []\n",
        "\n",
        "for name, group in grouped.groupby(level=0):\n",
        "  #print('---')\n",
        "  boolean = True\n",
        "  numero_fattura = name\n",
        "  mask1 = (prima_nota['ND ori.'] == numero_fattura)\n",
        "  #print(numero_fattura)\n",
        "  for name1, group in group.groupby(level=[0, 1]):\n",
        "    conto = name1[1]\n",
        "    ammontare = group.values[0][0]\n",
        "    #print(conto)\n",
        "    #print(ammontare)\n",
        "    mask2 = (prima_nota['Conto'] == conto)\n",
        "    if not (prima_nota.Importo[mask1][mask2].empty):\n",
        "      #print(prima_nota.Importo[mask1][mask2].values[0])\n",
        "      if (np.abs((prima_nota.Importo[mask1][mask2].values[0] - ammontare)) > 0.01):\n",
        "        boolean = False\n",
        "    else:\n",
        "      boolean = False\n",
        "  if boolean:\n",
        "    validated.append(numero_fattura)\n",
        "\n",
        "print(validated)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOQu-LICBeey",
        "outputId": "14b6a6a9-74fc-4358-eef9-8a27c60b7630"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       PrezzoTotale\n",
            "Numero      Conto                  \n",
            "12/1040     66/25/006       153.310\n",
            "12/871      66/25/005        82.940\n",
            "            66/25/006       161.670\n",
            "18420       66/25/006      1448.510\n",
            "19048       66/25/006      1671.570\n",
            "...                             ...\n",
            "8874/0      66/20/005       151.330\n",
            "            66/30/015        79.000\n",
            "            66/30/017        54.600\n",
            "            66/30/055         0.300\n",
            "FPR 1025/20 66/25/006        73.962\n",
            "\n",
            "[146 rows x 1 columns]\n",
            "['53138', '55496', '56723', '57898', '65226', '71285', '7699/0', '8874/0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creazione di un nuovo data_labeled con questi nuovi samples validati dagli ammontari in prima nota\n",
        "\n",
        "mask = []\n",
        "for i in list(data_unlabeled3.Numero):\n",
        "  boolean = False\n",
        "  if i in validated:\n",
        "    boolean = True\n",
        "  mask.append(boolean)\n",
        "\n",
        "data_labeled3 = data_unlabeled3[mask]\n",
        "data_labeled3.reset_index(inplace=True)\n",
        "data_labeled3 = data_labeled3.drop(['index', 'Conto'], axis=1)\n",
        "\n",
        "y_pred_validated = y_pred[mask]\n",
        "data_labeled3 = pd.concat(objs=[data_labeled3, pd.Series(y_pred_validated).rename('Conto')], axis=1)\n",
        "\n",
        "print(data_labeled3.shape)"
      ],
      "metadata": {
        "id": "bir2-Ce7S5iP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b53311-510a-4101-a821-7097391c0ac3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(152, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_labeled3 contiene solo le pseudo-labels validate subito perchè verosimilmente il modello predittivo non ha commesso nessun\n",
        "#errore. Però, esplorando lo spazio degli swap con A* se ne possono validare anche molte altre. \n",
        "\n",
        "non_validated = set(list(np.unique(data_unlabeled3.Numero))) - set(validated)\n",
        "print(len(non_validated))\n",
        "\n",
        "#A* viene quindi applicato per 34 fatture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY_QhJgTkJVz",
        "outputId": "dca81480-566e-4c5c-8276-0ae9c0718862"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A* viene applicato su tutte le 48 fatture (validate immediatamente e non) che raggruppano le 1049 righe con delle pseudo-labels.\n",
        "#Si riesce a determinare la sequenza di swap per validare le pseudo-labels per 38 fatture (per un totale di 747 righe) come riscontrabile dal confronto tra prima \n",
        "#nota e raggruppamento per ContoEsatto (cioè il conto assegnato dopo gli swap)\n",
        "\n",
        "df_Astar_validated = pd.read_excel('/content/pseudo_labels_validated2.xlsx')\n",
        "grouped2 = df_Astar_validated.groupby(['Numero', 'ContoEsatto']).sum()\n",
        "\n",
        "print(df_Astar_validated.shape)\n",
        "print(grouped2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pci1_jMFmbjK",
        "outputId": "e368eceb-10ea-462a-efee-92e61d3cff2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1049, 5)\n",
            "                         Unnamed: 0  PrezzoTotale\n",
            "Numero      ContoEsatto                          \n",
            "12/1040     66/25/005            68        76.680\n",
            "            66/25/006           102        76.630\n",
            "12/871      66/25/005           508        96.440\n",
            "            66/25/006          1769       148.170\n",
            "2069036018  66/25/005          3075       184.670\n",
            "...                             ...           ...\n",
            "8874/0      66/20/005          1197       151.330\n",
            "            66/30/015          1194        79.000\n",
            "            66/30/017           395        54.600\n",
            "            66/30/055           402         0.300\n",
            "FPR 1025/20 66/20/005          2212        73.962\n",
            "\n",
            "[134 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#valutazione delle performance dello pseudo labeling con validazione:\n",
        "#in df_Astar_validated, le fatture per cui l'euristica non ha funzionato hanno ContoEsatto = NaN, le rimuovo\n",
        "\n",
        "df_Astar_validated = df_Astar_validated[df_Astar_validated['ContoEsatto'].notna()]\n",
        "Astar_fatture = list(np.unique(df_Astar_validated.Numero))\n",
        "\n",
        "print(df_Astar_validated.shape)\n",
        "print(len(Astar_fatture))\n",
        "\n",
        "#Nel complesso si sono validate, grazie all'approccio semi-supervised, 747 righe su 1156 possibili (cioè il 65%)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN99bkKlrttb",
        "outputId": "b51d8a2a-a61b-46be-dddc-c31e70e8c664"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(747, 5)\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adesso le ulteriori pseudo-labels validate da A* devono essere aggiunte ai corrispondenti dati unsupervised di \n",
        "#data_unlabeled3 (cioè il dataset di samples unsupervised ripulito), creando un nuovo dataset supervised: data_labeled4\n",
        "\n",
        "mask = []\n",
        "for i in list(data_unlabeled3.Numero):\n",
        "  boolean = False\n",
        "  if i in Astar_fatture:\n",
        "    boolean = True\n",
        "  mask.append(boolean)\n",
        "\n",
        "data_labeled4 = data_unlabeled3[mask]\n",
        "data_labeled4.reset_index(inplace=True)\n",
        "data_labeled4 = data_labeled4.drop(['index', 'Conto'], axis=1)\n",
        "\n",
        "for numero_fattura in list(np.unique(data_labeled4.Numero)):\n",
        "  data_labeled4.loc[data_labeled4['Numero'] == numero_fattura, 'Conto'] = df_Astar_validated.loc[df_Astar_validated['Numero'] == numero_fattura, 'ContoEsatto'].values\n"
      ],
      "metadata": {
        "id": "RQmPCPVzsoww"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creazione di un dataset supervisionato esteso in cui ci sono tutte le coppie input-output ottenute dalla risoluzione\n",
        "#del knapsack problem (1805, data_labeled), più tutte quelle appena validate (747, data_labeled4)\n",
        "\n",
        "data_labeled5 = pd.concat(objs = [data_labeled, data_labeled4], axis=0)\n",
        "data_labeled5.reset_index(inplace=True)\n",
        "data_labeled5 = data_labeled5.drop(['index'], axis=1)\n",
        "\n",
        "print(data_labeled5.shape)\n",
        "\n",
        "print(data_labeled5.groupby('Conto').count())\n",
        "\n",
        "#In totale si hanno 2552 dati supervisionati, di cui 747 grazie ad A* (un'estensione del 41%)"
      ],
      "metadata": {
        "id": "w2Wn9H8Zh-hY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0745deab-8339-4567-ca5b-e50732642d9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2552, 1564)\n",
            "           Descrizione  Numero  PrezzoUnitario  PrezzoTotale  AliquotaIVA  \\\n",
            "Conto                                                                       \n",
            "18/40/501            1       1               1             1            1   \n",
            "66/05/006          790     790             790           790          790   \n",
            "66/20/005          344     344             344           344          344   \n",
            "66/25/005          300     300             300           300          300   \n",
            "66/25/006          516     516             516           516          516   \n",
            "66/25/505           12      12              12            12           12   \n",
            "66/25/506           34      34              34            34           34   \n",
            "66/25/507           22      22              22            22           22   \n",
            "66/25/508            1       1               1             1            1   \n",
            "66/25/509           53      53              53            53           53   \n",
            "66/30/015           48      48              48            48           48   \n",
            "66/30/017           11      11              11            11           11   \n",
            "66/30/055           93      93              93            93           93   \n",
            "66/30/060            1       1               1             1            1   \n",
            "68/05/005            1       1               1             1            1   \n",
            "68/05/025          293     293             293           293          293   \n",
            "68/05/133            1       1               1             1            1   \n",
            "68/05/290            2       2               2             2            2   \n",
            "68/05/320            4       4               4             4            4   \n",
            "68/05/385            4       4               4             4            4   \n",
            "68/05/407            1       1               1             1            1   \n",
            "68/05/490            7       7               7             7            7   \n",
            "70/05/101           12      12              12            12           12   \n",
            "88/20/035            1       1               1             1            1   \n",
            "\n",
            "           Year  Month  Day  CodiceTipo_  CodiceTipo_ARTICOLO  ...  yes  yoga  \\\n",
            "Conto                                                          ...              \n",
            "18/40/501     1      1    1            1                    1  ...    1     1   \n",
            "66/05/006   790    790  790          790                  790  ...  790   790   \n",
            "66/20/005   344    344  344          344                  344  ...  344   344   \n",
            "66/25/005   300    300  300          300                  300  ...  300   300   \n",
            "66/25/006   516    516  516          516                  516  ...  516   516   \n",
            "66/25/505    12     12   12           12                   12  ...   12    12   \n",
            "66/25/506    34     34   34           34                   34  ...   34    34   \n",
            "66/25/507    22     22   22           22                   22  ...   22    22   \n",
            "66/25/508     1      1    1            1                    1  ...    1     1   \n",
            "66/25/509    53     53   53           53                   53  ...   53    53   \n",
            "66/30/015    48     48   48           48                   48  ...   48    48   \n",
            "66/30/017    11     11   11           11                   11  ...   11    11   \n",
            "66/30/055    93     93   93           93                   93  ...   93    93   \n",
            "66/30/060     1      1    1            1                    1  ...    1     1   \n",
            "68/05/005     1      1    1            1                    1  ...    1     1   \n",
            "68/05/025   293    293  293          293                  293  ...  293   293   \n",
            "68/05/133     1      1    1            1                    1  ...    1     1   \n",
            "68/05/290     2      2    2            2                    2  ...    2     2   \n",
            "68/05/320     4      4    4            4                    4  ...    4     4   \n",
            "68/05/385     4      4    4            4                    4  ...    4     4   \n",
            "68/05/407     1      1    1            1                    1  ...    1     1   \n",
            "68/05/490     7      7    7            7                    7  ...    7     7   \n",
            "70/05/101    12     12   12           12                   12  ...   12    12   \n",
            "88/20/035     1      1    1            1                    1  ...    1     1   \n",
            "\n",
            "           yogurt  yonkers  zacapa  zenzero  zero  zuccheriera  zucchero  \\\n",
            "Conto                                                                      \n",
            "18/40/501       1        1       1        1     1            1         1   \n",
            "66/05/006     790      790     790      790   790          790       790   \n",
            "66/20/005     344      344     344      344   344          344       344   \n",
            "66/25/005     300      300     300      300   300          300       300   \n",
            "66/25/006     516      516     516      516   516          516       516   \n",
            "66/25/505      12       12      12       12    12           12        12   \n",
            "66/25/506      34       34      34       34    34           34        34   \n",
            "66/25/507      22       22      22       22    22           22        22   \n",
            "66/25/508       1        1       1        1     1            1         1   \n",
            "66/25/509      53       53      53       53    53           53        53   \n",
            "66/30/015      48       48      48       48    48           48        48   \n",
            "66/30/017      11       11      11       11    11           11        11   \n",
            "66/30/055      93       93      93       93    93           93        93   \n",
            "66/30/060       1        1       1        1     1            1         1   \n",
            "68/05/005       1        1       1        1     1            1         1   \n",
            "68/05/025     293      293     293      293   293          293       293   \n",
            "68/05/133       1        1       1        1     1            1         1   \n",
            "68/05/290       2        2       2        2     2            2         2   \n",
            "68/05/320       4        4       4        4     4            4         4   \n",
            "68/05/385       4        4       4        4     4            4         4   \n",
            "68/05/407       1        1       1        1     1            1         1   \n",
            "68/05/490       7        7       7        7     7            7         7   \n",
            "70/05/101      12       12      12       12    12           12        12   \n",
            "88/20/035       1        1       1        1     1            1         1   \n",
            "\n",
            "           zucher  \n",
            "Conto              \n",
            "18/40/501       1  \n",
            "66/05/006     790  \n",
            "66/20/005     344  \n",
            "66/25/005     300  \n",
            "66/25/006     516  \n",
            "66/25/505      12  \n",
            "66/25/506      34  \n",
            "66/25/507      22  \n",
            "66/25/508       1  \n",
            "66/25/509      53  \n",
            "66/30/015      48  \n",
            "66/30/017      11  \n",
            "66/30/055      93  \n",
            "66/30/060       1  \n",
            "68/05/005       1  \n",
            "68/05/025     293  \n",
            "68/05/133       1  \n",
            "68/05/290       2  \n",
            "68/05/320       4  \n",
            "68/05/385       4  \n",
            "68/05/407       1  \n",
            "68/05/490       7  \n",
            "70/05/101      12  \n",
            "88/20/035       1  \n",
            "\n",
            "[24 rows x 1563 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rimozione delle unità statistiche con target troppo rari (threshold = 5, incluso). La molteplicità dei target scende da 24 a 14.\n",
        "\n",
        "mask = (data_labeled5['Conto'] != '18/40/501')&(data_labeled5['Conto'] != '66/25/508')&(data_labeled5['Conto'] != '66/30/060')&(data_labeled5['Conto'] != '68/05/005')&(data_labeled5['Conto'] != '68/05/133')&(data_labeled5['Conto'] != '68/05/290')&(data_labeled5['Conto'] != '68/05/320')&(data_labeled5['Conto'] != '68/05/385')&(data_labeled5['Conto'] != '68/05/407')&(data_labeled5['Conto'] != '88/20/035')\n",
        "data_labeled5 = data_labeled5[mask]\n",
        "data_labeled5.reset_index(inplace=True)\n",
        "data_labeled5 = data_labeled5.drop(['index'], axis=1)\n",
        "print(data_labeled5.shape)\n",
        "\n",
        "#rimangono 2535 dati per training e test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sna8K0C1HiMJ",
        "outputId": "84c34124-5623-422f-ffe7-f6b5d105b6ff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2535, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#per rendere le performance confrontabili con il caso base senza estensione del dataset supervisionato grazie alle pseudo-labels\n",
        "#uso come test set lo stesso del notebook 1, ovvero il 30% finale di data_labeled: cioè le righe dalla 1264 alla 1804 di\n",
        "#data_labeled5\n",
        "\n",
        "data_test = data_labeled5.loc[1264:1804,:]\n",
        "\n",
        "data_train = data_labeled5.drop(data_test.index, axis=0)\n",
        "data_test.reset_index(inplace=True)\n",
        "data_test = data_test.drop(['index'], axis=1)\n",
        "data_train.reset_index(inplace=True)\n",
        "data_train = data_train.drop(['index'], axis=1)\n",
        "print(data_test.shape)\n",
        "print(data_train.shape)\n",
        "\n",
        "#In definitiva, su 5877 righe fattura iniziali, solo 2961 sono effettivamente associabili a un output in prima nota e la pipeline\n",
        "#adottata permette di etichettarne 2552, cioè l'86%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzbdXzMtJIbe",
        "outputId": "72288d47-bfa4-494e-d16f-b3463366addc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(541, 1564)\n",
            "(1994, 1564)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test dei soliti modelli RF e AdaBoost sul solito test set, ma dopo il training su data_train esteso grazie ai dati semi supervised\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = data_train.drop(['Conto', 'Descrizione', 'Numero'], axis=1)\n",
        "targets = data_train.Conto\n",
        "\n",
        "clf2 = RandomForestClassifier(n_estimators=100, max_depth=50, bootstrap = False)\n",
        "y_pred = clf2.fit(features, targets).predict(data_test.drop(['Conto', 'Numero', 'Descrizione'], axis = 1))\n",
        "print(accuracy_score(data_test.Conto, y_pred))\n",
        "print(len(y_pred))\n",
        "\n",
        "#la performance di accuracy è salita stabilmente sopra al 95%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpJwN3TFcw1C",
        "outputId": "67bc8561-4906-4667-9631-f6192c057161"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9519408502772643\n",
            "541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AdaBoost\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "clf2 = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=7), n_estimators=100)\n",
        "y_pred = clf2.fit(features, targets).predict(data_test.drop(['Conto', 'Numero', 'Descrizione'], axis = 1))\n",
        "print(accuracy_score(data_test.Conto, y_pred))\n",
        "\n",
        "#Per AdaBoost la performance non sembra variare (rimane tra 94% e 95%).\n",
        "#Sia nel caso di RF che di AdaBoost, gli errori nella matrice di confusione sono dello stesso tipo di prima, ma nel caso di RF,\n",
        "#grazie allo pseudo-labeling si è ottenuto un +1% di accuracy sullo stesso test set."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okAxCzBxftqQ",
        "outputId": "697eb2d4-fc6f-4679-872b-ff8b4239a7b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9426987060998152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tentativo CatBoost\n",
        "\n",
        "!pip3 install catboost\n",
        "import catboost as cb\n",
        "\n",
        "model_cat_def = cb.CatBoostClassifier(iterations=1000, learning_rate=0.1, max_depth=6)\n",
        "y_pred = model_cat_def.fit(features, targets).predict(data_test.drop(['Conto', 'Numero', 'Descrizione'], axis = 1))\n",
        "print(accuracy_score(data_test.Conto, y_pred))\n",
        "\n",
        "#Il tempo di training varia molto al variare della profondità, ma comunque essendo un metodo di boosting non servono\n",
        "#alberi molto profondi. Di base implementa il classico Gradient Boosting, con qualche miglioria, e la performance è circa 95%"
      ],
      "metadata": {
        "id": "cjHc3wh1GXGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dato che a seguito dello pseudo-labeling ottenuto grazie ad A* si ha un nuovo, esteso training set, si può creare un nuovo, esteso\n",
        "#dizionario per Bag of Words, che tenga in considerazione anche le parole che compaiono nei nuovi samples fornendo una descrizione piu completa.\n",
        "#Vanno eliminate da data_labeled5 le precedenti features testuali e aggiunte le nuove\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "data_labeled6 = data_labeled5.drop(data_labeled5.columns[[range(206, 1564)]], axis=1)\n",
        "data_test = data_labeled6.loc[1264:1804,:]\n",
        "data_train = data_labeled6.drop(data_test.index, axis=0)\n",
        "\n",
        "descr = data_labeled6.Descrizione\n",
        "descr_train = descr[data_train.index]\n",
        "descr_test = descr[data_test.index]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bag_train = vectorizer.fit_transform(list(descr_train))\n",
        "bag_train = pd.DataFrame(bag_train.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "bag_test = vectorizer.transform(list(descr_test))\n",
        "bag_test = pd.DataFrame(bag_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "data_train.reset_index(inplace=True)\n",
        "data_train = data_train.drop(['index'], axis=1)\n",
        "data_test.reset_index(inplace=True)\n",
        "data_test = data_test.drop(['index'], axis=1)\n",
        "bag_train.reset_index(inplace=True)\n",
        "bag_train = bag_train.drop(['index'], axis=1)\n",
        "bag_test.reset_index(inplace=True)\n",
        "bag_test = bag_test.drop(['index'], axis=1)\n",
        "\n",
        "data_train = pd.concat(objs=(data_train, bag_train), axis=1)\n",
        "data_test = pd.concat(objs=(data_test, bag_test), axis=1)\n",
        "\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIUUztOtKafZ",
        "outputId": "98244212-2bf9-4c7f-b4b5-42a6cc0b9f3d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1994, 1905)\n",
            "(541, 1905)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4616: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF: con profondità aumentata perchè ora ci sono più features\n",
        "\n",
        "features = data_train.drop(['Conto', 'Descrizione', 'Numero'], axis=1)\n",
        "targets = data_train.Conto\n",
        "\n",
        "clf2 = RandomForestClassifier(n_estimators=100, max_depth=75, bootstrap = False)\n",
        "y_pred = clf2.fit(features, targets).predict(data_test.drop(['Conto', 'Numero', 'Descrizione'], axis = 1))\n",
        "print(accuracy_score(data_test.Conto, y_pred))\n",
        "\n",
        "#usando il solito test set di sempre, l'accuracy è ora quasi del 96%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwuTV34cMrCI",
        "outputId": "d82ba951-2334-4c88-b229-76dfcfe1a72a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9593345656192237\n"
          ]
        }
      ]
    }
  ]
}
